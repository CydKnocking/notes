---
password: password
---

# Research diary

## 2024

### 0704

- ç”¨stable diffusionåšfinetuneï¼Œå¯ä»¥ç”¨ä½å¼€é”€å’Œä¸å¤šçš„æ•°æ®é›†åšfinetuneã€‚

- åšdepthçš„ï¼šRepurposing Diffusion-Based Image Generators for Monocular Depth Estimation (CVPR 2024)ï¼Œå¯ä»¥ä»é‡Œé¢å€Ÿé‰´conditionalçš„ç”¨æ³•ï¼Œä»¥åŠå¦‚ä½•æŠŠdepth imageè½¬æ¢åˆ°é€‚åˆdiffusionçš„æ¡†æ¶ï¼›åšdense matchingçš„ï¼šDIFFUSION MODEL FOR DENSE MATCHING (ICLR 2024)ï¼Œä»–ç”¨ä¸¤å¼ å›¾çš„global costä½œä¸ºconditionï¼Œä½†æ˜¯æ¡†æ¶è®¾è®¡ä¸Šè¿˜æ˜¯æœ‰ç‚¹æš´åŠ›ã€‚

### 0705

- DOTï¼ˆMatching 2D Images in 3D: Metric Relative Pose from Metric Correspondencesï¼‰ä¸ºå•¥æ¯”RAFTå’ŒCoTrackeræ•ˆæœè¿˜å¥½ï¼ŸDOTçš„å®éªŒè®¾è®¡å’Œæ•…äº‹æ˜¯æ€ä¹ˆè®²çš„ï¼Œå€¼å¾—çœ‹ä¸€çœ‹ã€‚

### 0706

- ç”¨covarianceå»ºæ¨¡point tracksä¹‹é—´çš„å…³è”æ€§ï¼Ÿ
  
  ä¸‰ä¸ªå¥½å¤„ï¼šé²æ£’ï¼ˆä»å›¾åƒä¸­å¯¹ç‚¹åštrackï¼Œå­¦çš„æ˜¯$\delta I$ï¼›è€Œå­¦ä¹ trackä¹‹é—´çš„covarianceï¼Œå­¦çš„æ˜¯$\delta I$æ•´ä½“çš„åˆ†å¸ƒç‰¹æ€§ï¼‰ï¼›é«˜æ•ˆï¼ˆå‡è½»æ•°æ®å†—ä½™å’Œå­¦ä¹ è´Ÿæ‹…ï¼Œå¯ä»¥ç”¨å°‘é‡çš„ç¨³å®šçš„ç‚¹ï¼Œè¡¨è¾¾æ•´å¼ å›¾é‡Œå…¶ä»–ç‚¹çš„è¿åŠ¨è¶‹åŠ¿ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥è¡¨è¾¾ç›¸æœºçš„è¿åŠ¨è¶‹åŠ¿ï¼‰ï¼›å¯ä»¥åšé¢„æµ‹ï¼ˆå­¦åˆ°çš„covarianceå¯ä»¥ç”¨ä½œé¢„æµ‹pointåœ¨ä¸‹ä¸€å¸§é‡Œçš„ç§»åŠ¨ï¼‰
  
  æ•°å­¦æ–¹æ³•ä¸Šå‚è€ƒLearning a Depth Covariance Functionï¼Œçœ‹çœ‹ä»–æ€ä¹ˆè¿›è¡Œçš„éšæœºè¿‡ç¨‹å»ºæ¨¡
  
  åå¤„ï¼šé‚£è¿™æ ·å°±è¦è®²point trackçš„æ•…äº‹äº†ï¼Ÿä¸ç®¡æ˜¯point trackingè¿˜æ˜¯optical flowï¼Œéƒ½éå¸¸å…³æ³¨åŠ¨æ€ç‰©ä½“ã€‚é‚£è¦åšåŠ¨æ€ç‰©ä½“ï¼Ÿ

- è€ƒè™‘ç”¨covariance functionåšoptical flowï¼Ÿè¿˜æ˜¯åškeypoint matchingï¼Ÿ

- Image encoderå¯ä»¥è€ƒè™‘ç”¨é¢„è®­ç»ƒçš„DIVOv2ã€‚

- å¦‚æœåšcovariance function+optical flowï¼Œé‚£éš¾ç‚¹å°±åœ¨äºï¼šdepth covariance functionæ˜¯ç”¨çš„UNet cnnç½‘ç»œï¼ŒRAFTç”¨çš„æ˜¯GRUï¼Œè¿™ä¸ªæ€ä¹ˆè°ƒé€šã€‚

### 0708

- dust3rï¼šèƒ½å¦åšåˆ°onlineï¼Œèƒ½å¦åšåˆ°sparse

### 0729

- rotation-invariant PPF (RIGA: Rotation-Invariant and Globally-Aware Descriptors for Point Cloud Registration sec3.2).

### 0731

- SuperPoint + Co-Tracker + COTR ?

### 0810

- COTR takes too much time... Consider using LoFTR/LightGlue?

### 0824

ECCV24 ç›¸å…³çš„è®ºæ–‡

- Grounding Image Matching in 3D with MASt3R (NAVER LABS Europe)
- **Learning to Make Keypoints Sub-Pixel Accurate** (Marc Pollefeys Group)
- X-Pose: Detecting Any Keypoints
- SRPose: Two-view Relative Pose Estimation with Sparse Keypoints


## 2025

### 0110

ä»Scholar Inboxä¸Šæ‰¾äº†2024çš„å’ŒVOç›¸å…³çš„æ–‡ç« ã€‚ç®€å•åšä¸ªç¬”è®°ã€‚

- [MambaVO: Deep Visual Odometry Based on Sequential Matching Refinement and Training Smoothing](https://arxiv.org/pdf/2412.20082)<br>
  ç”¨manbaåšVOï¼Œæœ‰çº¯VOç‰ˆå’ŒåŠ äº†å›ç¯çš„ä¸¤ä¸ªç‰ˆæœ¬ã€‚ç”¨MambaåŠ å¼ºmatchingï¼Œåšæ›´å¥½çš„åˆå§‹åŒ–ã€‚
- [RoMeO: Robust Metric Visual Odometry](https://arxiv.org/pdf/2412.11530)<br>
  DPVOåŠ äº†metricï¼Œä¸»è¦æ˜¯ç”¨äº†å¸¦metricçš„é¢„è®­ç»ƒç½‘ç»œæ¥ä¼°è®¡depthã€‚
- [**Leveraging Consistent Spatio-Temporal Correspondence for Robust Visual Odometry**](https://arxiv.org/pdf/2412.16923)<br>
  åœ¨droid-voä¸ŠåŠ äº†æ—¶åºè¿ç»­æ€§ï¼Œç”¨depthanything v2åŠ å…¥äº†ç©ºé—´çº¦æŸã€‚
- [KeyGS: A Keyframe-Centric Gaussian Splatting Method for Monocular Image Sequences](https://arxiv.org/pdf/2412.20767)<br>
  åœ¨videoä¸Šåšï¼ŒSfM+3dgsï¼Œå¹¶åŒæ—¶ä¼˜åŒ–ç›¸æœºä½å§¿å’Œåœ°å›¾ã€‚
- [SCENES: Subpixel Correspondence Estimation With Epipolar Supervision](https://arxiv.org/pdf/2401.10886)<br>
  matchingçš„æ¨¡å‹åœ¨æ–°çš„æ•°æ®é›†ä¸Šåšfinetuneï¼Œåªéœ€è¦poseæä¾›epipolar lineï¼ŒlossæŒ‡å¯¼åŒ¹é…çš„ç‚¹æœepipolar lineé è¿‘å°±è¡Œã€‚
- [YOLOPoint: Joint Keypoint and Object Detection](https://arxiv.org/pdf/2402.03989)<br>
  æŠŠYOLOv5å’ŒSuperPointç½‘ç»œç»“åˆï¼Œå¯ä»¥å®æ—¶çš„åŒæ—¶æ£€æµ‹keypointså’Œobjectsï¼ˆlow-levelå’Œhigh-levelç‰¹å¾ï¼‰
- [Incorporating Point Uncertainty in Radar SLAM](https://arxiv.org/pdf/2402.16082)<br>
- [VOOM: Robust Visual Object Odometry and Mapping using Hierarchical Landmarks](https://arxiv.org/pdf/2402.13609)<br>
  è§†è§‰-ç‰©ä½“slamï¼Œç”¨äº†high-level objectså’Œlow-level pointsä½œä¸ºå¤šå±‚æ¬¡çš„landmarksã€‚
- [Compact 3D Gaussian Splatting for Dense Visual SLAM](https://arxiv.org/pdf/2403.11247)<br>
  RGBD+3dgs SLAMã€‚
- [CodedVO: Coded Visual Odometry](https://arxiv.org/pdf/2407.18240)<br>
  å‘è¡¨åœ¨RALã€‚ç”¨äº†ç‰¹æ®Šçš„å…‰å­¦å…ƒä»¶æŠŠå¸¦scaleçš„æ·±åº¦ä¿¡æ¯ç»™ç¼–ç åˆ°imageä¸­ã€‚
- [SCIPaD: Incorporating Spatial Clues into Unsupervised Pose-Depth Joint Learning](https://arxiv.org/pdf/2407.05283)<br>
  éç›‘ç£å­¦depthå’Œposeï¼Œä¸ºäº†è§£å†³åŠ¨æ€ç‰©ä½“ï¼Œç”¨äº†å¸¦confidenceçš„optical flowä½œå¼•å¯¼ã€‚
- [Self-supervised Pretraining and Finetuning for Monocular Depth and Visual Odometry](https://arxiv.org/pdf/2406.11019)<br>
  è‡ªç›‘ç£å­¦depthå’Œposeï¼Œç”¨äº†åœ¨cross-view completion objectiveä¸Šå­¦ä¹ çš„pretrainedçš„æ¨¡å‹ï¼Œå†finetuneåˆ°æ— æ ‡æ³¨çš„æ•°æ®ä¸Šã€‚
- [Self-Supervised Geometry-Guided Initialization for Robust Monocular Visual Odometry](https://arxiv.org/pdf/2406.00929)<br>
  è‡ªç›‘ç£VOï¼Œä¸»è¦è§£å†³è‡ªåŠ¨é©¾é©¶åœºæ™¯ï¼ˆdriod-slamè¡¨ç°å¾ˆå·®ï¼‰çš„åŠ¨æ€ç‰©ä½“ã€é«˜é€Ÿè¡Œé©¶ã€æ€¥è½¬å¼¯ç­‰è¡¨ç°ä¸å¥½çš„é—®é¢˜ã€‚ç”¨äº†ä¸ªfrozen large-scale pre-trainedå•ç›®æ·±åº¦ä¼°è®¡çš„ç½‘ç»œï¼Œæ¥åˆå§‹åŒ–BAçš„æ·±åº¦ã€‚
- [TAMBRIDGE: Bridging Frame-Centered Tracking and 3D Gaussian Splatting for Enhanced SLAM](https://arxiv.org/pdf/2405.19614)<br>
  åº”å¯¹ä¼ æ„Ÿå™¨å™ªå£°ï¼Œè¿åŠ¨æ¨¡ç³Šï¼Œé•¿æ—¶slamã€‚ç¼äº†ORB VOå’Œonline 3dgsã€‚
- [MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization](https://arxiv.org/pdf/2405.06241)<br>
  ç¨€ç–VOï¼Œç”¨å…³é”®å¸§åšfast MVSç”¨ä»¥ç¨ å¯†3DGSã€‚
- [**Multi-Session SLAM with Differentiable Wide-Baseline Pose Optimization**](https://openaccess.thecvf.com//content/CVPR2024/papers/Lipson_Multi-Session_SLAM_with_Differentiable_Wide-Baseline_Pose_Optimization_CVPR_2024_paper.pdf)<br>
  æ™®æ—æ–¯é¡¿Jia Dengç»„çš„ï¼Œmulti-session slamã€‚å¯ä»¥è€ƒè™‘æŠŠå·²æœ‰çš„æ¡†æ¶ç»™æ‰©æˆmulti-sessionçš„ã€‚å¯ä»¥äº†è§£ä¸€ä¸‹multi-sessionçš„è®¾å®šã€‚ç›¸å…³æ–‡ç« [Asynchronous Multi-View SLAM](https://arxiv.org/pdf/2101.06562) ICRA2021
- [**Matching 2D Images in 3D: Metric Relative Pose from Metric Correspondences**](https://openaccess.thecvf.com//content/CVPR2024/papers/Barroso-Laguna_Matching_2D_Images_in_3D_Metric_Relative_Pose_from_Metric_CVPR_2024_paper.pdf)<br>
  æŠŠ2d-2dçš„åŒ¹é…ç»™æ‹“å±•åˆ°äº†åŠ å…¥3d metricï¼Œå¯ä»¥å‡ºå¸¦metricçš„ç›¸å¯¹ä½å§¿ã€‚
- [**Salient Sparse Visual Odometry with Pose-only Supervision**](https://arxiv.org/pdf/2404.04677)<br>
  RALçš„æ–‡ç« ï¼Œåœ¨DPVOåŸºç¡€ä¸Šæ”¹çš„ï¼Œç”¨è‡ªç›‘ç£çš„å…‰æµå¼•å¯¼é€‰æ‹©ç¨³å®šçš„ç‰¹å¾ç‚¹ã€‚
- [Incremental Joint Learning of Depth, Pose and Implicit Scene Representation on Monocular Camera in Large-scale Scenes](https://arxiv.org/pdf/2404.06050)<br>
  NeRF slamï¼Œvideoçš„å¢é‡å¼æ„å»ºnerfã€‚

ä»¥ä¸‹çš„éœ€æ•´ç†ï¼š

- [InCrowd-VI: A Realistic Visual-Inertial Dataset for Evaluating SLAM in Indoor Pedestrian-Rich Spaces for Human Navigation](https://arxiv.org/pdf/2411.14358)<br>
- [**MPVO: Motion-Prior based Visual Odometry for PointGoal Navigation**](https://arxiv.org/pdf/2411.04796)<br>
- [Enhanced Monocular Visual Odometry with AR Poses and Integrated INS-GPS for Robust Localization in Urban Environments](https://arxiv.org/pdf/2411.08231)<br>
- [BEV-ODOM: Reducing Scale Drift in Monocular Visual Odometry with BEV Representation](https://arxiv.org/pdf/2411.10195)<br>
- [MAC-VO: Metrics-aware Covariance for Learning-based Stereo Visual Odometry](https://arxiv.org/pdf/2409.09479)<br>
- [ORB-SfMLearner: ORB-Guided Self-supervised Visual Odometry with Selective Online Adaptation](https://arxiv.org/pdf/2409.11692)<br>
- [GEVO: Memory-Efficient Monocular Visual Odometry Using Gaussians](https://arxiv.org/pdf/2409.09295)<br>
- [Panoramic Direct LiDAR-assisted Visual Odometry](https://arxiv.org/pdf/2409.09287)<br>
- [Deep Patch Visual SLAM](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00272.pdf)<br>
- [Str-L Pose: Integrating Point and Structured Line for Relative Pose Estimation in Dual-Graph](https://arxiv.org/pdf/2408.15750)<br>
- [Towards Real-Time Gaussian Splatting: Accelerating 3DGS through Photometric SLAM](https://arxiv.org/pdf/2408.03825)<br>
- [Correspondence-Free SE(3) Point Cloud Registration in RKHS via Unsupervised Equivariant Learning](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/12030.pdf)<br>
- [GLIM: 3D Range-Inertial Localization and Mapping with GPU-Accelerated Scan Matching Factors](https://arxiv.org/pdf/2407.10344)<br>
- [Semi-Supervised Pipe Video Temporal Defect Interval Localization](https://arxiv.org/pdf/2407.15170)<br>
- [Attenuation-Aware Weighted Optical Flow with Medium Transmission Map for Learning-based Visual Odometry in Underwater terrain](https://arxiv.org/pdf/2407.13159)<br>
- [Robust Monocular Visual Odometry using Curriculum Learning](https://arxiv.org/pdf/2411.13438)<br>


### 0203

- [Dense-SfM: Structure from Motion with Dense Consistent Matching](https://arxiv.org/pdf/2501.14277)<br>
  2025/1æŒ‚åœ¨arxivï¼Œçœ‹ä¸Šå»åƒæ˜¯æŠ•cvprçš„ã€‚ç¨ å¯†ã€å¤šå¸§SfMï¼Œç”¨äº†3DGSå¸®åŠ©åšå¤šå¸§çš„åŒ¹é…ã€‚å…ˆåˆå§‹åŒ–ä¸€ä¸ªSfMå’Œä¸€ä¸ªé«˜æ–¯ï¼Œç„¶åä¼˜åŒ–é«˜æ–¯+è¿›è¡Œç¨ å¯†åŒ–ï¼Œä»é«˜æ–¯ä¸­å°†SfMçš„3Dç‚¹ç»™æŠ•å½±åˆ°æ–°çš„å¸§ï¼Œå»ºç«‹æ–°çš„matchå…³ç³»ï¼Œæœ€åå†ç”¨ç½‘ç»œå¯¹ç‚¹çš„tracksè¿›è¡Œrefinementï¼Œç”¨BAå¾—åˆ°refined SfMã€‚<br>
  å¯ä»¥å­¦å­¦ï¼šæ€ä¹ˆç»“åˆGSåšçš„track extensionï¼›å¯ä»¥å‚è€ƒtrack refinementçš„ç½‘ç»œè®¾è®¡ã€‚<br>
  æ²¡å¼€æºã€‚<br>
  å¯ä»¥ä»è¿™ç¯‡äº†è§£ä¸€ä¸‹sfmçš„å‡ ç±»æ–¹æ³•ï¼šdetector-based(colmap, pixsfm etc.), semi-dense matching(detector-free)(LoFTR/AspanTrans/MatchFormer + PixSfM/DFSfM), dense matching(RoMa/DKM + DFSfM/ours)ï¼ŒåŒæ—¶é¡ºä¾¿å¯ä»¥äº†è§£åŒ¹é…çš„æ–¹æ³•ã€‚

### 0301

- [MambaGlue: Fast and Robust Local Feature Matching With Mamba](https://arxiv.org/pdf/2502.00462)<br>
  æ ¸å¿ƒè®¾è®¡äº†MambaAttentionï¼Œä¸€ç§åŸºäºmambaçš„self-attentionå±‚ã€‚æé«˜äº†è¿è¡Œæ•ˆç‡ã€‚

### 0313 CVPR'25

#### SLAMç›¸å…³

- [MAGiC-SLAM: Multi-Agent Gaussian Globally Consistent SLAM](https://arxiv.org/pdf/2411.16785)<br>
  å¤šæ™ºèƒ½ä½“3dgs SLAMã€‚
- [MNE-SLAM: Multi-Agent Neural SLAM for Mobile Robots]()<br>
- [SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos](https://www.arxiv.org/pdf/2412.09401)<br>
  é™ˆå®æƒè€å¸ˆç»„çš„å·¥ä½œã€‚æŠŠDUSt3Ræ‰©å±•æˆäº†SLAMã€‚ä¸»è¦ç”¨sliding windowæ„å»ºsubmapï¼Œç„¶ååšå¯¹é½ã€‚
- [MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors]()

#### å…¶ä»–

- [**VGGT: Visual Geometry Grounded Transformer**](https://www.arxiv.org/pdf/2503.11651)<br>
  feed-forward networkï¼ŒåŒæ—¶å¯¹ä»»æ„æ•°é‡çš„å›¾åƒè¾“å…¥ï¼Œè¾“å‡ºç›¸æœºå‚æ•°ã€ç‚¹äº‘ã€æ·±åº¦å›¾ã€3Dç‚¹è·Ÿè¸ªã€‚åœ¨64å¼ A100ä¸Šè®­ç»ƒ9å¤©ã€‚<br>
  ç”¨tapvid_davisçš„ä¸€äº›åºåˆ—æµ‹äº†ä¸‹ï¼Œfailure caseæœ‰soapbox, scooter-black, pigs, parkour, motocross-jump, mbike-trickç­‰<br>
  è¿˜è¡Œçš„åºåˆ—loading, libbyç­‰<br>

  ä¸èƒ½æœ‰æ•ˆçš„å»é™¤åŠ¨æ€ç‰©ä½“çš„å½±å“ï¼Œå¯¹äºä¸€äº›éç»“æ„åŒ–åœºæ™¯ï¼ˆé‡å¤–ç­‰ï¼‰é‡å»ºä¸å¥½ï¼Œå¯¹äºåƒparkourè¿™æ ·è¿˜ç®—æœ‰ç»“æ„çš„ï¼Œä½†æ— çº¹ç†è¾ƒå¤§ï¼Œè§†è§’è½¬åŠ¨è¾ƒå¤§çš„é‡å»ºå¾—ä¹Ÿä¸å¥½ã€‚<br>
  æ„Ÿè§‰å¯¹äºè§†è§’è½¬åŠ¨è¿‡å¤§çš„ï¼Œé‡å»ºæ•ˆæœéƒ½ä¸å¤ªå¥½ã€‚<br>
  å¯¹äºå®¤å¤–åœºæ™¯ï¼Œå½“åŒ…å«ä¸€äº›æ·±åº¦è¾ƒè¿œçš„éƒ¨åˆ†ï¼Œæ•ˆæœä¸å¥½ã€‚

- [**MATCHA: Towards Matching Anything**](https://arxiv.org/pdf/2501.14945)<br>
  æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„â€œèåˆäº†å‡ ä½•ç‰¹å¾ã€è¯­ä¹‰ç‰¹å¾ã€å¯¹è±¡ç‰¹å¾â€çš„è§†è§‰ç‰¹å¾ï¼Œåœ¨å‡ ä½•åŒ¹é…ã€è¯­ä¹‰åŒ¹é…ã€ç‚¹çš„æ—¶åºtrackingä»»åŠ¡ä¸Šè¡¨è¾ƒå¥½ã€‚ä¸»è¦åŸºäºäº†DIFTå’ŒDINOv2è¿™ä¸¤ä¸ªå·¥ä½œã€‚<br>
  å›å¤´è¯»ä¸€ä¸‹ï¼šå½“å‰è§†è§‰ç‰¹å¾çš„ç›¸å…³å·¥ä½œï¼Œmatchingç›¸å…³çš„ï¼ˆå‡ ä½•ã€è¯­ä¹‰ï¼‰ã€point trackingã€ä»¥åŠè§†è§‰åŸºç¡€æ¨¡å‹ã€‚


### 0422

- [**TAPIP3D: Tracking Any Point in Persistent 3D Geometry**](https://www.arxiv.org/abs/2504.14717v1)<br>
  æŠŠå›¾åƒçš„2dç‰¹å¾unprojectæˆ3dç‰¹å¾äº‘ï¼Œåœ¨ç‰¹å¾äº‘ä¸Šç”¨knnåšattentionã€‚ç”¨äº†Mogeåšdepth estimatorï¼ŒMegaSaMä¼°è®¡ç›¸æœºå†…å¤–å‚ã€‚point tracksçš„iterativeæ›´æ–°å‚è€ƒäº†CoTracker3ã€‚<br>
  åœ¨3dç‚¹äº‘ä¸Šå–knnæ¯”è¾ƒæ…¢ï¼Œå¯ä»¥ä¼˜åŒ–(æ¯”å¦‚å‚è€ƒMASt3R-SLAMçš„ä¼˜åŒ–æ–¹æ³•ï¼Ÿ)<br>

### 0423

- [**Back on Track: Bundle Adjustment for Dynamic Scene Reconstruction**](https://arxiv.org/pdf/2504.14516)<br>
  LEAP-VOä½œè€…çš„æ–°ä½œï¼Œç»§ç»­ç”¨TAPåšåŠ¨æ€VOã€‚ç”¨äº†depthä¼°è®¡ç½‘ç»œ(ZoeDepth)ï¼Œå¯¹äºåŠ¨æ€ç‰©ä½“ä¸Šçš„pointåœ¨ä¼°è®¡trackæ—¶ï¼Œå¤šä¼°è®¡äº†ä¸€ä¸ªdynamic motionï¼ŒæŠŠåŠ¨æ€ç‰©ä½“çš„trackç»™è§£è€¦/æ¢å¤æˆé™æ€åœºæ™¯çš„trackã€‚ï¼Œå†ç»“åˆæ·±åº¦åšBAã€‚<br>
- [**Relative Pose Estimation through Affine Corrections of Monocular Depth Priors**](https://www.arxiv.org/pdf/2501.05446)<br>
  CVPR2025 highlight<br>
  å½“å‰æ·±åº¦ä¼°è®¡æ¨¡å‹ï¼Œåœ¨ä½¿ç”¨çš„æ—¶å€™ä»…ä»…è€ƒè™‘äº†scale factorï¼Œæ²¡è€ƒè™‘shift factorã€‚æ‰€ä»¥è¿™ç¯‡æ–‡ç« æå‡ºåœ¨æ±‚è§£/åŒ¹é…çš„æ—¶å€™ï¼ŒåŒæ—¶è¦è€ƒè™‘scaleå’Œshift factorã€‚è¿™ä¸ªæƒ³æ³•æˆ–è®¸ä¸æ˜¯å®ƒç¬¬ä¸€ä¸ªæå‡ºçš„ï¼Œä½†æ˜¯å®ƒç”¨è¿™ä¸ªæƒ³æ³•è®¾è®¡äº†å‡ ç§æƒ…å†µä¸‹çš„æ±‚è§£å™¨ï¼ˆcalibratedå’Œuncalibratedç­‰ï¼‰<br>
  ï¼ˆè¿™ç¯‡æ–‡ç« è¯´ï¼‰è¿™ä¸ªé—®é¢˜åº”è¯¥æ˜¯ç”±è®­ç»ƒæ—¶çš„æŸå¤±å‡½æ•°è®¾è®¡é—®é¢˜å¼•å…¥çš„ã€‚<br>
  ä¹‹å‰çš„å·¥ä½œï¼Œæ¯”å¦‚MonoSDFä¸­ï¼Œè®¾è®¡çš„depthä¼°è®¡ç½‘ç»œå…¶å®å°±æ˜¯affine invariantçš„ã€‚<br>

### 0503

å•ç›®åŠ¨æ€åœºæ™¯4dé‡å»ºç›¸å…³:

- [**MegaSaM: Accurate, Fast and Robust Structure and Motion from Casual Dynamic Videos**](https://mega-sam.github.io/)<br>
  åœ¨å¤§é‡æ•°æ®ä¸Šè®­ç»ƒï¼Œå¯¹ä»»æ„åŠ¨æ€è§†é¢‘è¿›è¡Œé‡å»º+ç›¸æœºä½å§¿ä¼°è®¡ã€‚<br>
  cvpr2025 best paperã€‚<br>
- [**TAPIP3D: Tracking Any Point in Persistent 3D Geometry**](https://www.arxiv.org/abs/2504.14717v1)<br>
  æŠŠå›¾åƒçš„2dç‰¹å¾unprojectæˆ3dç‰¹å¾äº‘ï¼Œåœ¨ç‰¹å¾äº‘ä¸Šç”¨knnåšattentionã€‚ç”¨äº†Mogeåšdepth estimatorï¼ŒMegaSaMä¼°è®¡ç›¸æœºå†…å¤–å‚ã€‚point tracksçš„iterativeæ›´æ–°å‚è€ƒäº†CoTracker3ã€‚<br>
  åœ¨3dç‚¹äº‘ä¸Šå–knnæ¯”è¾ƒæ…¢ï¼Œå¯ä»¥ä¼˜åŒ–(æ¯”å¦‚å‚è€ƒMASt3R-SLAMçš„ä¼˜åŒ–æ–¹æ³•ï¼Ÿ)<br>
  æ•ˆæœçœ‹ä¸Šå»è¿˜è¡Œï¼Œ

### 0614

Point tracking in CVPR2025

- [GS-DiT: Advancing Video Generation with Dynamic 3D Gaussian Fields through Efficient Dense 3D Point Tracking](https://arxiv.org/pdf/2501.02690)
- [Exploring Temporally-Aware Features for Point Tracking](https://arxiv.org/pdf/2501.12218)<br>
  ä¸€ä¸ªé’ˆå¯¹point trackingé—®é¢˜æ”¹è¿›çš„DIVOv2ç½‘ç»œï¼Œå¯ä»¥èšåˆæ—¶åºçš„featureï¼Œå¾—åˆ°çš„featureå¯ä»¥ç›´æ¥æ‹¿æ¥ç®—correlation mapã€‚<br>
- [Tracktention: Leveraging Point Tracking to Attend Videos Faster and Better](https://arxiv.org/pdf/2503.19904)
- [TimeTracker: Event-based Continuous Point Tracking for Video Frame Interpolation with Non-linear Motion](https://arxiv.org/pdf/2505.03116)


### 0628

- [LiVOS: Light Video Object Segmentation with Gated Linear Matching](https://www.alphaxiv.org/abs/2411.02818v1)<br>
  è§†é¢‘ç‰©ä½“åˆ†å‰²ã€‚æ”¹è¿›äº†ç©ºé—´-æ—¶é—´è®°å¿†ç½‘ç»œï¼ˆSTMï¼‰ï¼Œå…¶ä¸­ç”¨linear matchingæ›¿ä»£äº†ä¼ ç»Ÿstmä¸­çš„softmaxï¼›åŒæ—¶å¼•å…¥äº†gated linear matchingæœºåˆ¶ã€‚<br>
  ç½‘ç»œç»“æ„å’Œæ”¹åŠ¨æ€è·¯å¯ä»¥å‚è€ƒä¸€ä¸‹ã€‚
- [MINIMA: Modality Invariant Image Matching](https://arxiv.org/abs/2412.19412)<br>
  å¤šæ¨¡æ€å›¾åƒåŒ¹é…ã€‚ç”¨äº†ä¸€ä¸ªç”Ÿæˆæ¨¡å‹å»ç”Ÿæˆå¤šæ¨¡æ€å›¾åƒï¼Œæå‡ºäº†ä¸€å¥—æ¡†æ¶å¯ä»¥å¾®è°ƒloftr/lightglueç­‰ç¨€ç–/åŠç¨€ç–/ç¨ å¯†æ–¹æ³•ã€‚å¼€æºçš„ã€‚<br>
  å’Œè–›é£çš„matchaè€ƒè™‘çš„ä»»åŠ¡ç±»ä¼¼ï¼Œä½†æ˜¯æ€è·¯ä¸åŒã€‚<br>


### 0703

è¦ä¸è¦è¯•è¯•track-onåšvoï¼Œè§£å†³çº¯æ—‹è½¬é—®é¢˜ï¼Ÿåœºæ™¯æ˜¯å¤´æˆ´å¼è®¾å¤‡ï¼Œæ•°æ®é›†æ˜¯egopointsæˆ–è€…epic-fieldsã€‚

https://data.bris.ac.uk/data/dataset/3l8eci2oqgst92n14w2yqi5ytu<br>
https://data.bris.ac.uk/data/dataset/3h91syskeag572hl6tvuovwv4d<br>
https://epic-kitchens.github.io/2025<br>

çº¯æ—‹è½¬ç›¸å…³çš„æ–‡ç« ï¼š

- [Equivalent Constraints for Two-View Geometry: Pose Solution/Pure Rotation Identification and 3D Reconstruction](https://arxiv.org/pdf/1810.05863v1)<br>
  2019å¹´çš„æ–‡ç« <br>
- [RD-VIO: Robust Visual-Inertial Odometry for Mobile Augmented Reality in Dynamic Environments](https://www.alphaxiv.org/html/2310.15072v3)<br>
  24å¹´çš„æ–‡ç« ï¼Œç« å›½å³°è€å¸ˆç»„çš„ã€‚å¯¹äºè§†è§‰æœ‰çº¯æ—‹è½¬åˆ¤å®š+å»¶è¿Ÿä¸‰è§’åŒ–çš„æ“ä½œï¼Œå¯ä»¥å‚è€ƒä¸€ä¸‹ã€‚


### 0705

æ‰¾ä¸€ä¸‹å¤´æˆ´ç›¸æœº/vr/arä¹‹ç±»çš„æ•°æ®é›†

- epic-fields
- [WHU-Helmet Dataset](https://github.com/kafeiyin00/WHU-HelmetDataset?tab=readme-ov-file)
- [Ariaç³»åˆ—](https://www.projectaria.com/datasets/aea/)
- [Roller Coaster SLAM Dataset](https://github.com/Factor-Robotics/Roller-Coaster-SLAM-Dataset)
- [SimXR](https://arxiv.org/pdf/2403.06862v1)
- [ADVIO](https://github.com/AaltoVision/ADVIO)<br>
  DPVOåœ¨advio_01åºåˆ—ä¸Šå¾ˆå·®ï¼Œè¿™ä¸ªåºåˆ—ä¸­é—´æœ‰ä¸€æ®µåç”µæ¢¯ï¼Œç”»é¢ä¸­åªæœ‰æ‰¶æ¢¯å°é˜¶ï¼Œdpvoä»¥ä¸ºç›¸æœºæ²¡æœ‰ç§»åŠ¨ï¼Œå®é™…ä¸Šåœ¨ä¸Šå‡ã€‚<br>
  python demo.py --imagedir="/media/knocking/Expansion/datasets/advio/advio-01/iphone/frames.mov" --calib="/media/knocking/Expansion/datasets/advio/ADVIO/calibration/iphone-02.txt" --name advio_01 --viz --save_trajectory <br>
- [TUM-VIE](https://cvg.cit.tum.de/data/datasets/visual-inertial-event-dataset)<br>
  DPVOåœ¨running-hardåºåˆ—ä¸Šå¾ˆå·®ï¼Œè¿™ä¸ªåºåˆ—è¿åŠ¨æ¨¡ç³Šå¾ˆå¤šï¼Œäººæ‹¿ç€ç›¸æœºè·‘å¾—å¾ˆå¿«ã€‚<br>
  python demo.py --imagedir /media/knocking/Expansion/datasets/TUM_VIE/running-hard-vi_gt_data/left_images --calib /media/knocking/Expansion/datasets/TUM_VIE/calibB_left_1024x1024.txt --name "running-hard" --viz --save_trajectory <br>
  track-onåœ¨è¿åŠ¨æåº¦æ¨¡ç³Šçš„æƒ…å†µä¸‹ä¹Ÿå¾ˆå·®ï¼Œä»¥åŠåœ¨è¿™ç§åœºæ™¯ä¸‹å¦‚ä½•é€‰æ‹©queryéœ€è¦å¥½å¥½é€‰ä¸€ä¸‹ã€‚


### 0716

[ICCV'25 paperlist](https://iccv.thecvf.com/Conferences/2025/AcceptedPapers)

**Trackç›¸å…³ï¼š**

- [BlinkTrack: Feature Tracking over 80 FPS via Events and Images](https://arxiv.org/pdf/2409.17981)
- A Linear N-Point Solver for Structure and Motion from Asynchronous Tracks
- [SpatialTrackerV2: Advancing 3D Point Tracking with Explicit Camera Motion](https://arxiv.org/pdf/2507.12462)
- [Tracking Tiny Drones against Clutter: Large-Scale Infrared Benchmark with Motion-Centric Adaptive Algorithm]
- [Language Decoupling with Fine-grained Knowledge Guidance for Referring Multi-object Tracking]
- [GSOT3D: Towards Generic 3D Single Object Tracking in the Wild](https://arxiv.org/pdf/2412.02129)
- [Is Tracking really more challenging in First Person Egocentric Vision?]
- [XTrack: Multimodal Training Boosts RGB-X Video Object Trackers](https://arxiv.org/pdf/2405.17773)
- LA-MOTR: End-to-End Multi-Object Tracking by Learnable Association
- MVTrajecter: Multi-View Pedestrian Tracking with Trajectory Motion Cost and Trajectory Appearance Cost
- [**Online Dense Point Tracking with Streaming Memory**](https://arxiv.org/pdf/2503.06471)<br>
  [github](https://github.com/DQiaole/SPOT)
- [**TrackAny3D: Transferring Pretrained 3D Models for Category-unified 3D Point Cloud Tracking**](http://www.cssclab.cn/downloadfile/2025/TrackAny3D_Transferring%20Pretrained%203D%20Models%20for%20Category-unified%203D%20Point%20Cloud%20Tracking.pdf)
- Inter Inertial Poser: Multi-Human Motion Tracking from Sparse Inertial Sensors and Pairwise Inter-Sensor Distances 
- SMSTracker: Tri-path Score Mask Sigma Fusion for Multi-Modal Tracking
- [St4RTrack: Simultaneous 4D Reconstruction and Tracking in the World](https://arxiv.org/pdf/2504.13152)
- [General Compression Framework for Efficient Transformer Object Tracking](https://arxiv.org/pdf/2409.17564)
- [Street Gaussians without 3D Object Tracker](https://arxiv.org/pdf/2412.05548)
- [Event-aided Dense and Continuous Point Tracking: Everywhere and Anytime](https://openreview.net/pdf?id=1GIVx7COef)
- [CoTracker3: Simpler and Better Point Tracking by Pseudo-Labelling Real Videos](https://arxiv.org/pdf/2410.11831)
- COVTrack: Continuous Open-Vocabulary Multi-Object Tracking via Adaptive Multi-Cue Fusion
- [UMDATrack: Unified Multi-Domain Adaptive Tracking Under Adverse Weather Conditions](https://arxiv.org/pdf/2507.00648)
- CAT: A Unified Click-and-Track Framework for Realistic Tracking
- [Attention to Trajectory: Trajectory-Aware Open-Vocabulary Tracking](https://arxiv.org/pdf/2503.08145)
- [What You Have is What You Track: Adaptive and Robust Multimodal Tracking]
- [Multi-View 3D Point Tracking](https://arxiv.org/pdf/2508.21060)
- MATE: Motion-Augmented Temporal Consistency for Event-based Point Tracking
- M$^2$EIT:Multi-Domain Mixture of Experts for Robust Neural Inertial Tracking
- [Efficient Track Anything](https://arxiv.org/pdf/2411.18933)<br>
  [github](https://github.com/yformer/EfficientTAM)<br>
- [AllTracker: Efficient Dense Point Tracking at High Resolution](https://arxiv.org/pdf/2506.07310)<br>
  [github.io](https://alltracker.github.io/)<br>
- ASCENT: Annotation-free Self-supervised Contrastive Embeddings for 3D Neuron Tracking in Fluorescence Microscopy
- [Temporal Unlearnable Examples: Preventing Personal Video Data from Unauthorized Exploitation by Object Tracking](https://arxiv.org/pdf/2507.07483)
- [VOVTrack: Exploring the Potentiality in Raw Videos for Open-Vocabulary Multi-Object Tracking](https://arxiv.org/pdf/2410.08529)
- [**Back on Track: Bundle Adjustment for Dynamic Scene Reconstruction**](https://arxiv.org/pdf/2504.14516)
- ReTracker: Exploring Image Matching for Robust Online Any Point Tracking
- [Decouple and Track: Benchmarking and Improving Video Diffusion Transformers For Motion Transfer](https://arxiv.org/pdf/2503.17350)
- [TrackVerse: A Large-scale Dataset of Object Tracks for Visual Representation Learning](https://github.com/MMPLab/TrackVerse)
- [TAPNext: Tracking Any Point (TAP) as Next Token Prediction](https://arxiv.org/pdf/2504.05579)
- [CoopTrack: Exploring End-to-End Learning for Efficient Cooperative Sequential Perception](https://github.com/zhongjiaru/CoopTrack)

**Odometryç›¸å…³:**

- [Splat-LOAM: Gaussian Splatting LiDAR Odometry and Mapping](https://arxiv.org/pdf/2503.17491)

**SLAMç›¸å…³ï¼š**

- [SuperEvent: Cross-Modal Learning of Event-based Keypoint Detection for SLAM](https://arxiv.org/pdf/2504.00139)
- [Outdoor Monocular SLAM with Global Scale-Consistent 3D Gaussian Pointmaps](https://arxiv.org/pdf/2507.03737)
- [SEGS-SLAM: Structure-enhanced 3D Gaussian Splatting SLAM with Appearance Embedding](https://segs-slam.github.io/)
- [DyGS-SLAM: Real-Time Accurate Localization and Gaussian Reconstruction for Dynamic Scenes]()
- [ToF-Splatting: Dense SLAM using Sparse Time-of-Flight Depth and Multi-Frame Integration](https://arxiv.org/pdf/2504.16545)
- [Benchmarking Egocentric Visual-Inertial SLAM at City Scale]()
- [4D Gaussian Splatting SLAM](https://arxiv.org/pdf/2503.16710)
- [Underwater Visual SLAM with Depth Uncertainty and Medium Modeling]()

**keypointç›¸å…³ï¼š**

- [RIPE: Reinforcement Learning on Unlabeled Image Pairs for Robust Keypoint Extraction](https://arxiv.org/pdf/2507.04839)
- SuperEvent: Cross-Modal Learning of Event-based Keypoint Detection for SLAM
- Towards Annotation-Free Evaluation: KPAScore for Human Keypoint Detection
- VoxelKP: A Voxel-based Network Architecture for Human Keypoint Estimation in LiDAR Data
- [ZeroKey: Point-Level Reasoning and Zero-Shot 3D Keypoint Detection from Large Language Models](https://arxiv.org/pdf/2412.06292)
- [ReassembleNet: Learnable Keypoints and Diffusion for 2D Fresco Reconstruction](https://arxiv.org/pdf/2505.21117)
- [Sequential keypoint density estimator: an overlooked baseline of skeleton-based video anomaly detection](https://arxiv.org/pdf/2506.18368)
- [Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection](https://arxiv.org/pdf/2507.07994)

**matchingç›¸å…³ï¼š**

- [Towards Open-World Generation of Stereo Images and Unsupervised Matching](https://arxiv.org/pdf/2503.12720)
- Focal Plane Visual Feature Generation and Matching on a Pixel Processor Array
- [Diving into the Fusion of Monocular Priors for Generalized Stereo Matching](https://arxiv.org/pdf/2505.14414)
- Partially Matching Submap Helps: Uncetainty Modeling and Propagation for Text to Point Cloud Localization
- [Learning Few-Step Diffusion Models by Trajectory Distribution Matching](https://arxiv.org/pdf/2503.06674)
- [MAVFlow: Preserving Paralinguistic Elements with Conditional Flow Matching for Zero-Shot AV2AV Multilingual Translation](https://arxiv.org/pdf/2503.11026)
- [RobuSTereo: Robust Zero-Shot Stereo Matching under Adverse Weather](https://arxiv.org/pdf/2507.01653v1)
- [EMatch: A Unified Framework for Event-based Optical Flow and Stereo Matching](https://arxiv.org/pdf/2407.21735)
- MDP-Omni: Parameter-free Multimodal Depth Prior-based Sampling for Omnidirectional Stereo Matching
- SGAD: Semantic and Geometric-aware Descriptor for Local Feature Matching
- [Learning Dense Feature Matching via Lifting Single 2D Image to 3D Space]()
- [BANet: Bilateral Aggregation Network for Mobile Stereo Matching](https://arxiv.org/pdf/2503.03259)
- [Learning Robust Stereo Matching in the Wild with Selective Mixture-of-Experts](https://arxiv.org/pdf/2507.04631)
- [**Stereo Any Video: Temporally Consistent Stereo Matching**](https://arxiv.org/pdf/2503.05549)
- [Global Regulation and Excitation via Attention Tuning for Stereo Matching]()
- [ZeroStereo: Zero-shot Stereo Matching from Single Images](https://github.com/Windsrain/ZeroStereo?tab=readme-ov-file)
- CasP: Improving Semi-Dense Feature Matching Pipeline Leveraging Cascaded Correspondence Priors for Guidance
- [POMATO: Marrying Pointmap Matching with Temporal Motions for Dynamic 3D Reconstruction](https://arxiv.org/pdf/2504.05692)
- [ArgMatch: Adaptive Refinement Gathering for Efficient Dense Matching]()
- [**CoMatch: Dynamic Covisibility-Aware Transformer for Bilateral Subpixel-Level Semi-Dense Image Matching**](https://arxiv.org/pdf/2503.23925)
- [**EDM: Efficient Deep Feature Matching**](https://arxiv.org/pdf/2503.05122)
- [**Mind the Gap: Aligning Vision Foundation Models to Image Feature Matching**](https://www.arxiv.org/pdf/2507.10318v1)
- [Fast Globally Optimal and Geometrically Consistent 3D Shape Matching](https://arxiv.org/pdf/2504.06385)
- ReTracker: Exploring Image Matching for Robust Online Any Point Tracking

### 0719

å¾—çœ‹çœ‹IROSå’ŒICRAçš„list

- [Self-supervised Pretraining and Finetuning for Monocular Depth and Visual Odometry](https://arxiv.org/pdf/2406.11019)
- [Self-Supervised Learning of Monocular Visual Odometry and Depth with Uncertainty-Aware Scale Consisten](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10610075)


### 0721

è¿™ä¸ªå¾—çœ‹ä¸€ä¸‹<br>

- [$\pi^3$: Scalable Permutation-Equivariant Visual Geometry Learnin](https://arxiv.org/pdf/2507.13347)<br>


### 0722

æ¸…åæœ€è¿‘å‡ºäº†ä¸ªStreamVGGTï¼Œå¥½åƒæ˜¯videoè¾“å…¥èŒƒå¼/å¢é‡å¼çš„ï¼Œå¯ä»¥çœ‹ä¸€ä¸‹<br>

- [Streaming 4D Visual Geometry Transformer](https://arxiv.org/pdf/2507.11539), [ä¸»é¡µ](https://wzzheng.net/StreamVGGT/)<br>

è¿™ä¸ªç»„å¥½åƒæ¯”è¾ƒå¤šonline memoryçš„æ–‡ç« ï¼Œä¸€ä½œ[Wenzhao Zhengçš„ä¸»é¡µ](https://wzzheng.net/)


### 0807

VLAçš„ä¸€ä¸ªç»¼è¿°<br>

- [A Survey on Vision-Language-Action Models: An Action Tokenization Perspective](https://www.arxiv.org/pdf/2507.01925)


### 0901

- [Efficient Motion Prompt Learning for Robust Visual Tracking](https://www.arxiv.org/pdf/2505.16321v1)<br>
  é‡Œé¢å…³äºç©ºé—´ä½ç½®ç¼–ç å’Œæ—¶é—´ä½ç½®ç¼–ç çš„å°trickå›å¤´å¯ä»¥è¯•è¯•ï¼ˆEq.(3)ï¼‰ã€‚<br>


### 0904

#### [SpatialTrackerV2: 3D Point Tracking Made Easy](https://github.com/henry123-boy/SpaTrackerV2)

tag: `ICCV'25`, `3D`, `multi-view`

è¯¦ç»†è¯»ä¸€ä¸‹SpatialTrackerv2çš„è®ºæ–‡ã€‚

3. ä¼°è®¡æŸ¥è¯¢ç‚¹çš„3Dè½¨è¿¹$\mathcal{T}$æ—¶ï¼Œå°†å…¶åˆ†è§£æˆäº†ç›¸æœºè¿åŠ¨$\mathcal{T}_{ego}$å’Œç‰©ä½“è¿åŠ¨$\mathcal{T}_{object}$ä¸¤éƒ¨åˆ†ã€‚<br>
   
   1. $\mathcal{T}_{ego}$
      
      åˆå§‹çš„æ·±åº¦ä¼°è®¡å’Œç›¸æœºè¿åŠ¨ï¼šåŸºäºVGGTã€‚
  
   2. è”åˆä½å§¿ä¼˜åŒ–
      
      æå‡º**SyncFormer**ï¼Œè¿­ä»£åœ°åŒæ—¶ä¼˜åŒ–ï¼šUVç©ºé—´çš„è½¨è¿¹$\mathcal{T}^{2d}$ï¼›ç›¸æœºåæ ‡ç³»çš„è½¨è¿¹$\mathcal{T}^{3d}$ï¼›å¯è§åº¦æƒé‡$p^{vis}$ï¼›åŠ¨æ€æƒé‡$p^{dyn}$ã€‚ç›¸æœºçš„ä½å§¿$\mathcal{P}$ç”¨BAå¾—åˆ°ã€‚

      2D embeddingså’ŒCotracker3ä¸€æ ·ï¼Œ3D embeddingsåŒ…å«3dç›¸å…³æ€§ç‰¹å¾ç­‰ã€‚å…¶ä¸­ï¼Œ3dç›¸å…³æ€§ç‰¹å¾æ˜¯åœ¨å½’ä¸€åŒ–point mapä¸­å½“å‰çš„ç‚¹ä¸é‚»å±…ç‚¹çš„ç›¸å¯¹ä½ç§»è¿›è¡Œharmonic positional encodingå¾—åˆ°çš„ï¼Œå¹¶ä¸”åœ¨å¤šåˆ†è¾¨ç‡ä¸Šéƒ½è¿›è¡Œäº†ç‰¹å¾ç¼–ç ã€‚

      SyncFormerè°ƒæ•´å®Œä¸€è½®$\mathcal{T}_{k+1}^{2d}, \mathcal{T}_{k+1}^{3d}, p_{k+1}^{dyn}, p_{k+1}^{vis}$åï¼Œé€šè¿‡Procrustes analysiså¯¹é½3dè½¨è¿¹åˆ°ä¸–ç•Œåæ ‡ç³»ï¼Œæ„å»ºBAä¼˜åŒ–å¾—åˆ°ç›¸æœºä½å§¿$\mathcal{P}_{k+1}$ã€‚
    
   3. è®­ç»ƒ

      åœ¨17ä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒã€‚ï¼ˆå•Šâ€¦â€¦å¥½å¤šğŸ˜å¥½å–œæ¬¢ï¼‰åˆ†ä¸ºä¸‰å¤§ç±»ï¼šå¸¦track gt, pose gtçš„RGB-Dæ•°æ®ï¼›å¸¦pose gtçš„RGB-Dæ•°æ®ï¼›ä»…æœ‰pose gtæˆ–æ— æ ‡æ³¨çš„ã€‚

      è®­ç»ƒåˆ†ä¸‰ä¸ªé˜¶æ®µã€‚ä¸€é˜¶æ®µï¼Œè®­ç»ƒå‰ç«¯çš„ç½‘ç»œï¼ˆVGGTæ”¹çš„ä¼°è®¡è§†é¢‘æ·±åº¦å’Œåˆå§‹ç›¸æœºä½å§¿ï¼‰ï¼Œ64å¼ H20ã€‚äºŒé˜¶æ®µï¼Œè®­ç»ƒSyncFormerï¼Œ8å¼ H20è®­3å¤©ã€‚ä¸‰é˜¶æ®µï¼Œå›ºå®šå‰ç«¯ç½‘ç»œä¸­çš„äº¤æ›¿æ³¨æ„åŠ›å±‚ï¼Œè®­æ•´ä¸ªæ¡†æ¶ã€‚

4. å®éªŒç»“æœ
   
   ä¸»è¦ç»“æœæ˜¯åœ¨TAPIP-3Dä¸Šå¯¹æ¯”3d trackingçš„ç²¾åº¦ã€‚åœ¨3d point trackingä¸Šæ˜¯sotaã€‚

   æ·±åº¦ä¼°è®¡ï¼Œåœ¨å®¤å†…(tum dyn, bonn, sintel)å’Œå®¤å¤–(kitti, sintel)å«åŠ¨æ€ç‰©ä½“çš„æ•°æ®é›†ï¼Œæ¯”VGGTå’ŒMegaSamå¥½ï¼ˆå„æœ‰ä¼˜åŠ£ï¼‰ã€‚

   ç›¸æœºä½å§¿ä¼°è®¡ï¼Œåœ¨å®¤å†…å¤–ï¼ˆtum dyn, lightspeed, sintelï¼‰ï¼Œå’ŒMegaSamå·®ä¸å¤šã€‚

   2D trackingä¹Ÿæ˜¯SOTAã€‚




#### Related works about point tracking

Refer to `papers/point_tracking`


### 1005

- [TTT3R: 3D RECONSTRUCTION AS TEST-TIME TRAINING](https://www.arxiv.org/pdf/2509.26645v1)
  
  è§£å†³é•¿åºåˆ—çš„åŠ¨æ€é‡å»ºé—®é¢˜ã€‚åœ¨transformerçš„æƒé‡æ›´æ–°é‡Œï¼Œç»™memoryåšæ›´æ–°æ—¶ï¼ŒåŠ äº†ä¸ªweightï¼Œä½¿å¾—æ¯ä¸€æ­¥æ›´æ–°çš„é‡å‡å°‘ã€‚
  
  æ ‹çˆ·è¯´å¾ˆtrickï¼ŒCut3ræ˜¯è¿™ç¯‡æ–‡ç« ä¸»è¦å¯¹æ¯”çš„å·¥ä½œä¹‹ä¸€ï¼Œcut3ræ˜¯rnnå¼çš„ï¼Œå¦‚æœupdateæ¬¡æ•°è¿‡å¤šï¼Œä¼šå¿˜è®°ä¹‹å‰çš„ä¸œè¥¿ï¼ˆæ¯”å¦‚è®­ç»ƒçš„æ—¶å€™æ˜¯30æ¬¡ï¼Œä½†æµ‹è¯•æ›´é•¿åºåˆ—å°±ä¸è¡Œï¼‰ï¼Œä½†æ˜¯å¯ä»¥ç”¨å…³é”®å¸§çš„æ›´æ–°ç­–ç•¥ï¼Œå¯¹äºé•¿åºåˆ—è€Œè¨€ä¸ç”¨æ¯æ­¥éƒ½æ›´æ–°ï¼Œè¿™ç§æƒ…å†µä¸‹cut3rä¹Ÿèƒ½è·‘ä¸‹æ¥ã€‚è¿™ç¯‡æ–‡ç« é‡Œï¼Œå®ƒå¯ä»¥ç»™æ›´æ–°é‡åŠ å¾ˆå°çš„weightï¼Œä¹Ÿèƒ½è¾¾åˆ°â€œä¸å¿˜è®°å†å²ä¿¡æ¯â€çš„æ•ˆæœã€‚

ä»Šæ—¥å®Œæˆï¼š

- [x] ç”¨SpaTrackerV2åŸæœ¬çš„å¯è§†åŒ–ï¼ŒæŠŠtapvid-3d benchmark gtç»™å¯è§†åŒ–äº†ã€‚adtå’ŒpstudioåŸºæœ¬æ˜¯å¯¹çš„ï¼Œdrivetrackçš„å¤–å‚å¤„ç†ä¸å¤ªå¯¹ï¼Œå›å¤´å†çœ‹çœ‹ã€‚ä»¥åŠtapvid-3dçš„depthæ„Ÿè§‰ä¸å¤ªå¥½å•Šï¼Œscaleåœ¨é£˜ï¼Œè€Œä¸”å’Œtracked pointçš„tracksæœ‰ä¸€ç‚¹ç‚¹åˆä¸ä¸Šï¼Œå¯èƒ½æ˜¯visualizationçš„é—®é¢˜ï¼ˆé‡Œé¢å¯¹depthåšäº†rescaleï¼‰ã€‚


### 1006

**paper reading:**

- [Dense Optical Tracking: Connecting the Dots](https://www.alphaxiv.org/pdf/2312.00786)
  
  CVPR'24

  ç”¨trackeråšç¨€ç–è¿½è¸ªï¼Œç„¶ååšæœ€é‚»è¿‘æ’å€¼æ’å‡ºå¯†é›†å…‰æµï¼Œç„¶åå†åšå…‰æµä¼˜åŒ–ã€‚

  åœ¨CVOå…‰æµçš„benchmarkï¼Œå’ŒTAP point trackingä¸¤ä¸ªbenchmarkä¸Šå¯¹æ¯”ã€‚åœ¨TAPä¸Šï¼Œfirstæ¨¡å¼çš„trackingå’Œcotrackerç›¸å½“ï¼Œstridedæ¨¡å¼ä¸‹æ˜¯sotaã€‚ï¼ˆ*è¿™ä¸ªæ„Ÿè§‰å¯ä»¥ç†è§£ï¼Œå› ä¸ºç›´è§‚ä¸Šå…‰æµå¯¹äºæ„å»ºé•¿æ—¶trackingä¸å¦‚point trackingçš„æ–¹æ³•*ï¼‰

  é€‰ç‚¹ç­–ç•¥ï¼š
  - ç”¨ä¸€ä¸ªé¢„è®­ç»ƒçš„å…‰æµæ¨¡å‹å…ˆä¼°è®¡ä¸¤å¸§çš„è¿åŠ¨åœºï¼Œç”¨Sobel filterç›‘æµ‹è¿åŠ¨è¾¹ç•Œ
  - 50\%çš„ç‚¹éšæœºé‡‡æ ·åœ¨è¿åŠ¨è¾¹ç•Œé™„è¿‘5ä¸ªpxå†…ï¼Œå¦ä¸€åŠåœ¨æ•´ä¸ªå›¾åƒä¸­éšæœºé‡‡æ ·ã€‚


**ä»Šæ—¥ï¼š**

- SpaTrackerV2çš„ä»£ç åªç»™äº†demoï¼Œæ²¡æœ‰ç»™trainingå’Œevaluationï¼Œè€Œè¿™ä¸¤éƒ¨åˆ†æœ‰ç‰¹åˆ«å¤šçš„ç»†èŠ‚ï¼Œä¸å¤ªå¥½å¼„
- 3d trackerè¿˜æ²¡åœ¨EgoPointsè¿™ç§é•¿æ—¶ï¼ˆè™½ç„¶2dï¼‰çš„benchmarkä¸Šæµ‹è¿‡ã€‚

- TAPIP3Då¯ä»¥load npzè¿›è¡Œinference:
  - video: (72, 480, 640, 3), uint8, 0, 255
  - intrinsics: (72, 3, 3), float32, 0.0, 615.357421875
  - extrinsics: (72, 4, 4), float32, 0.0, 1.0
  - depths: (72, 480, 640), float32, 0.0, 65.53500366210938

**æ˜å¤©TODOï¼š**

- [ ] TAPIP3Dæ„Ÿè§‰æ¯”è¾ƒå¥½followï¼Œçœ‹çœ‹èƒ½ä¸èƒ½åœ¨è¿™ä¸Šé¢æå®šè®­ç»ƒï¼Ÿ
- [ ] åœ¨EgoPointsè¿™ä¸ªbenchmarkä¸Šæµ‹ä¸€ä¸‹ï¼Ÿ


### 1007

**ä»Šæ—¥ï¼š**

- EgoPointsæ²¡æœ‰ç›¸æœºä½å§¿ã€å†…å¤–å‚æ ‡æ³¨ã€‚


### 1008

**ä»Šæ—¥ï¼š**

SpaTrackerV2çš„å¯¹æ¯”å®éªŒï¼Œå¯¹äºqueryç‚¹å‡ºç”»é¢åˆè¿›ç”»é¢çš„æƒ…å†µï¼š
- å°†è§†é¢‘ä¸­é—´çš„å¸§ç»™åˆ æ‰ï¼Œåªä¿ç•™äº†å¼€å¤´å’Œæœ«å°¾queryç‚¹éƒ½åœ¨ç”»é¢é‡Œçš„ç‰‡æ®µã€‚ä¾ç„¶trackä¸ä¸Šã€‚
- ä¸ç®¡æ˜¯å¦åˆ é™¤ä¸­é—´çš„å¸§ï¼Œå‰ç«¯VGGTç»™å‡ºçš„ç»“æœéƒ½æ˜¯å¥½çš„ã€‚ä½å§¿æ˜¯åé¢trackç½‘ç»œé‡Œä¼˜åŒ–è¿‡ç¨‹ä¸­å‡ºé”™äº†ã€‚

- æŠŠPi3åŠ åˆ°SpatialTrackerV2é‡Œäº†ï¼Œæ­£åœ¨æµ‹âœŒ


### 1009

**ä»Šæ—¥ï¼š**

Track-On2å‡ºäº†ï¼Œç”¨äº†DINOv3åšç‰¹å¾ã€‚
- track-on2ä»£ç æå®šâœŒ
- track-on2çš„è®­ç»ƒé›†æ˜¯cotracker3çš„kubric_movi_f (120 frames/seq)ï¼Œå’Œcotrackerä¹‹å‰çš„kubric_movi_fä¸ä¸€æ ·ï¼Œä»¥å‰æ˜¯24å¸§çš„åºåˆ—ã€‚åœ¨ä¸‹è½½äº†ã€‚


### 1013

ç”¨åˆ°äº†memoryçš„æ–¹æ³•ï¼š
Spann3R, CUT3R, TTT3R, PreF3R


### 1014

1. St4RTrackçš„ä»£ç è·‘é€šäº†ï¼Œä½†æˆ‘çš„æ•…äº‹æ˜¯å¦è¦ç”¨è¿™ä¸ªcode baseä¿®æ”¹ï¼Œè¿˜å¾—å†çœ‹çœ‹ã€‚
2. å¦‚æœåªæ˜¯ä¸ºäº†target online 3d point tracking in ego-motion sequencesï¼Œæ„Ÿè§‰å¯ä»¥ç”¨RGBDçš„è¾“å…¥ï¼ˆåŠ ä¸€ä¸ªzoedepthä¹‹ç±»çš„ï¼‰ï¼Œå›ºå®šç›¸æœºåæ ‡ç³»ï¼Œä¸ç”¨é‚£ä¹ˆçº ç»“ä½å§¿çš„é—®é¢˜ï¼Œåªéœ€è¦show online 3d trackingå¹¶ä¸”èƒ½å¤„ç†ego-motionä¸­ç‚¹æ¶ˆå¤±åˆå‡ºç°çš„é—®é¢˜
   1. è¦ä¹ˆä¹Ÿå¯ä»¥ç”¨3ræ¥ä¼°è®¡ä¸¤å¸§çš„correspondencesï¼Œåˆ©ç”¨è¿™ä¸ªç»“æœæ¥åšre-identifyingï¼ŒåŒæ—¶ä¹Ÿèƒ½å¾—åˆ°depthå’Œç›¸å¯¹ä½å§¿ã€‚

Depthç°åœ¨ç”¨äº†ZoeDepthï¼Œä¹Ÿå¯ä»¥ç”¨mogeï¼Ÿ


### 1015

é£å“¥ä¸¥é€‰ï¼š[WorldMirror: Universal 3D World Reconstruction with Any-Prior Prompting](https://www.arxiv.org/pdf/2510.10726)


### 1016

åœ¨å¾€track-on2ç½‘ç»œé‡Œçš„feature mapé‡ŒåŠ ä¸€ä¸ª3dçš„positional encodingã€‚

å…¶ä»–å·¥ä½œçš„åšæ³•ï¼š
- [MBPTrack: Improving 3D Point Cloud Tracking with Memory Networks and Box Priors](https://openaccess.thecvf.com/content/ICCV2023/papers/Xu_MBPTrack_Improving_3D_Point_Cloud_Tracking_with_Memory_Networks_and_ICCV_2023_paper.pdf)<br>
  çº¯3dç‚¹äº‘trackingçš„ã€‚åªåœ¨attentionå±‚çš„queryå’Œkeyä¸Šï¼Œç»™coordinatesåŠ äº†positional embeddings.<br>
  å®ƒçš„å‰ä½œæ˜¯[CXTrack: Improving 3D Point Cloud Tracking with Contextual Information](https://www.arxiv.org/pdf/2211.08542)ï¼Œä¹Ÿæ˜¯è¿™ä¹ˆåšçš„ã€‚<br>
  ä¸è¿‡è¿™ä¸¤ç¯‡æ–‡ç« æœ¬èº«çš„è¾“å…¥æ˜¯3dç‚¹äº‘ï¼Œç”¨çš„æ˜¯DGCNNå¯¹ç‚¹äº‘è¿›è¡Œçš„encodingã€‚


### 1028

è¯»è¯»è®ºæ–‡ï¼š
- [POMATO: Marrying Pointmap Matching with Temporal Motions for Dynamic 3D Reconstruction](https://www.alphaxiv.org/abs/2504.05692v2)
  ICCV'25ï¼ŒDust3rç½‘ç»œæ”¹çš„ã€‚


### 1106

MapAnythingåœ¨æœ¬åœ°æµ‹è¯•ï¼Œ512*512å›¾åƒï¼Œ6å¸§0.88ç§’é‡å»ºï¼Œ20å¸§1.79ç§’é‡å»ºã€‚


### 1109

åœ¨offset headä¸ŠåŠ¨åŠ¨æ‰‹è„šï¼Œå¤šåŠ ä¸€äº›trajectoryçš„/3dçš„ä¿¡æ¯ä½œä¸ºè¾“å…¥ï¼š
- è€ƒè™‘æŠŠ2d/3d trajectory(çš„offset)ç»™encode
- è¦ä¸è¦æŠŠcamera pose / rayä¹Ÿç»™encodeï¼Œæˆ–è€…æŠŠMapAnythingçš„ç›¸åº”tokenç»™ç”¨èµ·æ¥

æƒ³èµ·äº†eccv2022 SimpleReconåŠ metadataâ€¦â€¦
- feature dot product: å›¾åƒç‰¹å¾çš„ç›¸ä¼¼åº¦
- ray directions (normalized): ç›¸æœºåæ ‡ç³»ä¸‹çš„3dä¿¡æ¯
- reference plane depth: å•ç›®çš„3dä¿¡æ¯
- reference frame reprojected depths
- relative ray angles: ray directionsä¹‹é—´çš„è§’åº¦
- relative pose distance: ç›®æ ‡å¸§å’Œæºå¸§ä¹‹é—´çš„ç›¸æœºåæ ‡è·ç¦»
- depth validity masks


### 1111

Goal: æŠŠtapvid-3d benchmarkå†™è¿›evaluationé‡Œ
- [x] åŠ è½½tapvid-3dæ•°æ®é›†
- [ ] ç”¨mapanythingç»™tapvid-3dç”Ÿæˆdepthç­‰3dä¿¡æ¯
- [x] æŠŠ2dç»“æœç»™liftåˆ°3d
- [x] æµ‹è¯•

Goal: åœ¨è®­ç»ƒä¸­åŠ å…¥3dçš„è®°å¿†å’Œçº¦æŸ
- [x] åŠ è½½movi_fæ—¶ï¼ŒåŠ è½½depthå’Œextrinsicsç­‰ä¿¡æ¯
- [x] data augmentation on depth ...
- [ ] æŠŠ2d trackæ­£ç¡®æŠ•å½±åˆ°3d world coordinate
- [ ] æ·»åŠ æ–°çš„ç½‘ç»œï¼Œå¤„ç†3dçš„è®°å¿†


### 1117

Brain Storming

è¦å­¦åˆ°pointåœ¨3dç©ºé—´ä¸­çš„è¿åŠ¨å’Œæ—¶ç©ºè¿ç»­æ€§ï¼Œåœ¨æ–¹æ³•/ä»»åŠ¡å»ºæ¨¡ä¸Šå°è¯•ä¸¤ä¸ªæ”¹åŠ¨
1. ç›®å‰çš„3d point trackerç½‘ç»œè¾“å‡ºæ˜¯(x_t, y_t, z_t)ï¼Œè¦é¢„æµ‹è¿åŠ¨ï¼Œåº”è¯¥å­¦åˆ°çš„æ˜¯(dx, dy, dz)çš„ä¿¡æ¯ã€‚æ›´è¿›ä¸€æ­¥ï¼Œå¯ä»¥ä»åŠ¨åŠ›å­¦çš„è§’åº¦ï¼Œå­¦pointè¿åŠ¨çš„(direction, distance)ã€‚åœ¨æ­¤åŸºç¡€ä¸Šï¼Œå¯ä»¥åŸºäºå†å²çš„(direction, distance)æ¥ä¿®æ­£å½“å‰å¸§çš„ä¼°è®¡ã€‚
2. å¯ä¸å¯ä»¥æŠŠç‚¹åœ¨3dçš„è¿åŠ¨ç»™å»ºæ¨¡æˆåˆ†ç±»+å›å½’é—®é¢˜ï¼Œæ¯”å¦‚ç”¨**å­˜æœ‰è‹¥å¹²ä¸ªç¨€ç–è¿åŠ¨æ–¹å‘çš„codebook+refiner**è¿™ç§æ¡†æ¶æ¥åšã€‚


### 1121

Brain Storming

é¢„æµ‹confidence/uncertainty æ”¹æˆ é¢„æµ‹å›¾åƒäºŒç»´ç©ºé—´ä¸­çš„ä¸ç¡®å®šæ€§(2x2åæ–¹å·®çŸ©é˜µ)/ä¸–ç•Œä¸‰ç»´ç©ºé—´ä¸­çš„ä¸ç¡®å®šæ€§(3x3åæ–¹å·®çŸ©é˜µ)ã€‚RoMa v2ç”¨äº†è¿™ä¸ªï¼Œåœ¨æœ‰è¿åŠ¨æ¨¡ç³Šçš„æƒ…å†µä¸‹ï¼Œè¯¯å·®åœ¨æ¨¡ç³Šçš„æ–¹å‘ä¸Šå¯èƒ½æ›´å¤§ã€‚
