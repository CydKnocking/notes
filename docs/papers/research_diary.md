---
password: password
---

# Research diary

## 2024

### 0704

- ç”¨stable diffusionåšfinetuneï¼Œå¯ä»¥ç”¨ä½å¼€é”€å’Œä¸å¤šçš„æ•°æ®é›†åšfinetuneã€‚

- åšdepthçš„ï¼šRepurposing Diffusion-Based Image Generators for Monocular Depth Estimation (CVPR 2024)ï¼Œå¯ä»¥ä»é‡Œé¢å€Ÿé‰´conditionalçš„ç”¨æ³•ï¼Œä»¥åŠå¦‚ä½•æŠŠdepth imageè½¬æ¢åˆ°é€‚åˆdiffusionçš„æ¡†æ¶ï¼›åšdense matchingçš„ï¼šDIFFUSION MODEL FOR DENSE MATCHING (ICLR 2024)ï¼Œä»–ç”¨ä¸¤å¼ å›¾çš„global costä½œä¸ºconditionï¼Œä½†æ˜¯æ¡†æ¶è®¾è®¡ä¸Šè¿˜æ˜¯æœ‰ç‚¹æš´åŠ›ã€‚

### 0705

- DOTï¼ˆMatching 2D Images in 3D: Metric Relative Pose from Metric Correspondencesï¼‰ä¸ºå•¥æ¯”RAFTå’ŒCoTrackeræ•ˆæœè¿˜å¥½ï¼ŸDOTçš„å®éªŒè®¾è®¡å’Œæ•…äº‹æ˜¯æ€ä¹ˆè®²çš„ï¼Œå€¼å¾—çœ‹ä¸€çœ‹ã€‚

### 0706

- ç”¨covarianceå»ºæ¨¡point tracksä¹‹é—´çš„å…³è”æ€§ï¼Ÿ
  
  ä¸‰ä¸ªå¥½å¤„ï¼šé²æ£’ï¼ˆä»å›¾åƒä¸­å¯¹ç‚¹åštrackï¼Œå­¦çš„æ˜¯$\delta I$ï¼›è€Œå­¦ä¹ trackä¹‹é—´çš„covarianceï¼Œå­¦çš„æ˜¯$\delta I$æ•´ä½“çš„åˆ†å¸ƒç‰¹æ€§ï¼‰ï¼›é«˜æ•ˆï¼ˆå‡è½»æ•°æ®å†—ä½™å’Œå­¦ä¹ è´Ÿæ‹…ï¼Œå¯ä»¥ç”¨å°‘é‡çš„ç¨³å®šçš„ç‚¹ï¼Œè¡¨è¾¾æ•´å¼ å›¾é‡Œå…¶ä»–ç‚¹çš„è¿åŠ¨è¶‹åŠ¿ï¼ŒåŒæ—¶ä¹Ÿå¯ä»¥è¡¨è¾¾ç›¸æœºçš„è¿åŠ¨è¶‹åŠ¿ï¼‰ï¼›å¯ä»¥åšé¢„æµ‹ï¼ˆå­¦åˆ°çš„covarianceå¯ä»¥ç”¨ä½œé¢„æµ‹pointåœ¨ä¸‹ä¸€å¸§é‡Œçš„ç§»åŠ¨ï¼‰
  
  æ•°å­¦æ–¹æ³•ä¸Šå‚è€ƒLearning a Depth Covariance Functionï¼Œçœ‹çœ‹ä»–æ€ä¹ˆè¿›è¡Œçš„éšæœºè¿‡ç¨‹å»ºæ¨¡
  
  åå¤„ï¼šé‚£è¿™æ ·å°±è¦è®²point trackçš„æ•…äº‹äº†ï¼Ÿä¸ç®¡æ˜¯point trackingè¿˜æ˜¯optical flowï¼Œéƒ½éå¸¸å…³æ³¨åŠ¨æ€ç‰©ä½“ã€‚é‚£è¦åšåŠ¨æ€ç‰©ä½“ï¼Ÿ

- è€ƒè™‘ç”¨covariance functionåšoptical flowï¼Ÿè¿˜æ˜¯åškeypoint matchingï¼Ÿ

- Image encoderå¯ä»¥è€ƒè™‘ç”¨é¢„è®­ç»ƒçš„DIVOv2ã€‚

- å¦‚æœåšcovariance function+optical flowï¼Œé‚£éš¾ç‚¹å°±åœ¨äºï¼šdepth covariance functionæ˜¯ç”¨çš„UNet cnnç½‘ç»œï¼ŒRAFTç”¨çš„æ˜¯GRUï¼Œè¿™ä¸ªæ€ä¹ˆè°ƒé€šã€‚

### 0708

- dust3rï¼šèƒ½å¦åšåˆ°onlineï¼Œèƒ½å¦åšåˆ°sparse

### 0729

- rotation-invariant PPF (RIGA: Rotation-Invariant and Globally-Aware Descriptors for Point Cloud Registration sec3.2).

### 0731

- SuperPoint + Co-Tracker + COTR ?

### 0810

- COTR takes too much time... Consider using LoFTR/LightGlue?

### 0824

ECCV24 ç›¸å…³çš„è®ºæ–‡

- Grounding Image Matching in 3D with MASt3R (NAVER LABS Europe)
- **Learning to Make Keypoints Sub-Pixel Accurate** (Marc Pollefeys Group)
- X-Pose: Detecting Any Keypoints
- SRPose: Two-view Relative Pose Estimation with Sparse Keypoints


## 2025

### 0110

ä»Scholar Inboxä¸Šæ‰¾äº†2024çš„å’ŒVOç›¸å…³çš„æ–‡ç« ã€‚ç®€å•åšä¸ªç¬”è®°ã€‚

- [MambaVO: Deep Visual Odometry Based on Sequential Matching Refinement and Training Smoothing](https://arxiv.org/pdf/2412.20082)<br>
  ç”¨manbaåšVOï¼Œæœ‰çº¯VOç‰ˆå’ŒåŠ äº†å›ç¯çš„ä¸¤ä¸ªç‰ˆæœ¬ã€‚ç”¨MambaåŠ å¼ºmatchingï¼Œåšæ›´å¥½çš„åˆå§‹åŒ–ã€‚
- [RoMeO: Robust Metric Visual Odometry](https://arxiv.org/pdf/2412.11530)<br>
  DPVOåŠ äº†metricï¼Œä¸»è¦æ˜¯ç”¨äº†å¸¦metricçš„é¢„è®­ç»ƒç½‘ç»œæ¥ä¼°è®¡depthã€‚
- [**Leveraging Consistent Spatio-Temporal Correspondence for Robust Visual Odometry**](https://arxiv.org/pdf/2412.16923)<br>
  åœ¨droid-voä¸ŠåŠ äº†æ—¶åºè¿ç»­æ€§ï¼Œç”¨depthanything v2åŠ å…¥äº†ç©ºé—´çº¦æŸã€‚
- [KeyGS: A Keyframe-Centric Gaussian Splatting Method for Monocular Image Sequences](https://arxiv.org/pdf/2412.20767)<br>
  åœ¨videoä¸Šåšï¼ŒSfM+3dgsï¼Œå¹¶åŒæ—¶ä¼˜åŒ–ç›¸æœºä½å§¿å’Œåœ°å›¾ã€‚
- [SCENES: Subpixel Correspondence Estimation With Epipolar Supervision](https://arxiv.org/pdf/2401.10886)<br>
  matchingçš„æ¨¡å‹åœ¨æ–°çš„æ•°æ®é›†ä¸Šåšfinetuneï¼Œåªéœ€è¦poseæä¾›epipolar lineï¼ŒlossæŒ‡å¯¼åŒ¹é…çš„ç‚¹æœepipolar lineé è¿‘å°±è¡Œã€‚
- [YOLOPoint: Joint Keypoint and Object Detection](https://arxiv.org/pdf/2402.03989)<br>
  æŠŠYOLOv5å’ŒSuperPointç½‘ç»œç»“åˆï¼Œå¯ä»¥å®æ—¶çš„åŒæ—¶æ£€æµ‹keypointså’Œobjectsï¼ˆlow-levelå’Œhigh-levelç‰¹å¾ï¼‰
- [Incorporating Point Uncertainty in Radar SLAM](https://arxiv.org/pdf/2402.16082)<br>
- [VOOM: Robust Visual Object Odometry and Mapping using Hierarchical Landmarks](https://arxiv.org/pdf/2402.13609)<br>
  è§†è§‰-ç‰©ä½“slamï¼Œç”¨äº†high-level objectså’Œlow-level pointsä½œä¸ºå¤šå±‚æ¬¡çš„landmarksã€‚
- [Compact 3D Gaussian Splatting for Dense Visual SLAM](https://arxiv.org/pdf/2403.11247)<br>
  RGBD+3dgs SLAMã€‚
- [CodedVO: Coded Visual Odometry](https://arxiv.org/pdf/2407.18240)<br>
  å‘è¡¨åœ¨RALã€‚ç”¨äº†ç‰¹æ®Šçš„å…‰å­¦å…ƒä»¶æŠŠå¸¦scaleçš„æ·±åº¦ä¿¡æ¯ç»™ç¼–ç åˆ°imageä¸­ã€‚
- [SCIPaD: Incorporating Spatial Clues into Unsupervised Pose-Depth Joint Learning](https://arxiv.org/pdf/2407.05283)<br>
  éç›‘ç£å­¦depthå’Œposeï¼Œä¸ºäº†è§£å†³åŠ¨æ€ç‰©ä½“ï¼Œç”¨äº†å¸¦confidenceçš„optical flowä½œå¼•å¯¼ã€‚
- [Self-supervised Pretraining and Finetuning for Monocular Depth and Visual Odometry](https://arxiv.org/pdf/2406.11019)<br>
  è‡ªç›‘ç£å­¦depthå’Œposeï¼Œç”¨äº†åœ¨cross-view completion objectiveä¸Šå­¦ä¹ çš„pretrainedçš„æ¨¡å‹ï¼Œå†finetuneåˆ°æ— æ ‡æ³¨çš„æ•°æ®ä¸Šã€‚
- [Self-Supervised Geometry-Guided Initialization for Robust Monocular Visual Odometry](https://arxiv.org/pdf/2406.00929)<br>
  è‡ªç›‘ç£VOï¼Œä¸»è¦è§£å†³è‡ªåŠ¨é©¾é©¶åœºæ™¯ï¼ˆdriod-slamè¡¨ç°å¾ˆå·®ï¼‰çš„åŠ¨æ€ç‰©ä½“ã€é«˜é€Ÿè¡Œé©¶ã€æ€¥è½¬å¼¯ç­‰è¡¨ç°ä¸å¥½çš„é—®é¢˜ã€‚ç”¨äº†ä¸ªfrozen large-scale pre-trainedå•ç›®æ·±åº¦ä¼°è®¡çš„ç½‘ç»œï¼Œæ¥åˆå§‹åŒ–BAçš„æ·±åº¦ã€‚
- [TAMBRIDGE: Bridging Frame-Centered Tracking and 3D Gaussian Splatting for Enhanced SLAM](https://arxiv.org/pdf/2405.19614)<br>
  åº”å¯¹ä¼ æ„Ÿå™¨å™ªå£°ï¼Œè¿åŠ¨æ¨¡ç³Šï¼Œé•¿æ—¶slamã€‚ç¼äº†ORB VOå’Œonline 3dgsã€‚
- [MGS-SLAM: Monocular Sparse Tracking and Gaussian Mapping with Depth Smooth Regularization](https://arxiv.org/pdf/2405.06241)<br>
  ç¨€ç–VOï¼Œç”¨å…³é”®å¸§åšfast MVSç”¨ä»¥ç¨ å¯†3DGSã€‚
- [**Multi-Session SLAM with Differentiable Wide-Baseline Pose Optimization**](https://openaccess.thecvf.com//content/CVPR2024/papers/Lipson_Multi-Session_SLAM_with_Differentiable_Wide-Baseline_Pose_Optimization_CVPR_2024_paper.pdf)<br>
  æ™®æ—æ–¯é¡¿Jia Dengç»„çš„ï¼Œmulti-session slamã€‚å¯ä»¥è€ƒè™‘æŠŠå·²æœ‰çš„æ¡†æ¶ç»™æ‰©æˆmulti-sessionçš„ã€‚å¯ä»¥äº†è§£ä¸€ä¸‹multi-sessionçš„è®¾å®šã€‚ç›¸å…³æ–‡ç« [Asynchronous Multi-View SLAM](https://arxiv.org/pdf/2101.06562) ICRA2021
- [**Matching 2D Images in 3D: Metric Relative Pose from Metric Correspondences**](https://openaccess.thecvf.com//content/CVPR2024/papers/Barroso-Laguna_Matching_2D_Images_in_3D_Metric_Relative_Pose_from_Metric_CVPR_2024_paper.pdf)<br>
  æŠŠ2d-2dçš„åŒ¹é…ç»™æ‹“å±•åˆ°äº†åŠ å…¥3d metricï¼Œå¯ä»¥å‡ºå¸¦metricçš„ç›¸å¯¹ä½å§¿ã€‚
- [**Salient Sparse Visual Odometry with Pose-only Supervision**](https://arxiv.org/pdf/2404.04677)<br>
  RALçš„æ–‡ç« ï¼Œåœ¨DPVOåŸºç¡€ä¸Šæ”¹çš„ï¼Œç”¨è‡ªç›‘ç£çš„å…‰æµå¼•å¯¼é€‰æ‹©ç¨³å®šçš„ç‰¹å¾ç‚¹ã€‚
- [Incremental Joint Learning of Depth, Pose and Implicit Scene Representation on Monocular Camera in Large-scale Scenes](https://arxiv.org/pdf/2404.06050)<br>
  NeRF slamï¼Œvideoçš„å¢é‡å¼æ„å»ºnerfã€‚

ä»¥ä¸‹çš„éœ€æ•´ç†ï¼š

- [InCrowd-VI: A Realistic Visual-Inertial Dataset for Evaluating SLAM in Indoor Pedestrian-Rich Spaces for Human Navigation](https://arxiv.org/pdf/2411.14358)<br>
- [**MPVO: Motion-Prior based Visual Odometry for PointGoal Navigation**](https://arxiv.org/pdf/2411.04796)<br>
- [Enhanced Monocular Visual Odometry with AR Poses and Integrated INS-GPS for Robust Localization in Urban Environments](https://arxiv.org/pdf/2411.08231)<br>
- [BEV-ODOM: Reducing Scale Drift in Monocular Visual Odometry with BEV Representation](https://arxiv.org/pdf/2411.10195)<br>
- [MAC-VO: Metrics-aware Covariance for Learning-based Stereo Visual Odometry](https://arxiv.org/pdf/2409.09479)<br>
- [ORB-SfMLearner: ORB-Guided Self-supervised Visual Odometry with Selective Online Adaptation](https://arxiv.org/pdf/2409.11692)<br>
- [GEVO: Memory-Efficient Monocular Visual Odometry Using Gaussians](https://arxiv.org/pdf/2409.09295)<br>
- [Panoramic Direct LiDAR-assisted Visual Odometry](https://arxiv.org/pdf/2409.09287)<br>
- [Deep Patch Visual SLAM](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/00272.pdf)<br>
- [Str-L Pose: Integrating Point and Structured Line for Relative Pose Estimation in Dual-Graph](https://arxiv.org/pdf/2408.15750)<br>
- [Towards Real-Time Gaussian Splatting: Accelerating 3DGS through Photometric SLAM](https://arxiv.org/pdf/2408.03825)<br>
- [Correspondence-Free SE(3) Point Cloud Registration in RKHS via Unsupervised Equivariant Learning](https://www.ecva.net/papers/eccv_2024/papers_ECCV/papers/12030.pdf)<br>
- [GLIM: 3D Range-Inertial Localization and Mapping with GPU-Accelerated Scan Matching Factors](https://arxiv.org/pdf/2407.10344)<br>
- [Semi-Supervised Pipe Video Temporal Defect Interval Localization](https://arxiv.org/pdf/2407.15170)<br>
- [Attenuation-Aware Weighted Optical Flow with Medium Transmission Map for Learning-based Visual Odometry in Underwater terrain](https://arxiv.org/pdf/2407.13159)<br>
- [Robust Monocular Visual Odometry using Curriculum Learning](https://arxiv.org/pdf/2411.13438)<br>


### 0203

- [Dense-SfM: Structure from Motion with Dense Consistent Matching](https://arxiv.org/pdf/2501.14277)<br>
  2025/1æŒ‚åœ¨arxivï¼Œçœ‹ä¸Šå»åƒæ˜¯æŠ•cvprçš„ã€‚ç¨ å¯†ã€å¤šå¸§SfMï¼Œç”¨äº†3DGSå¸®åŠ©åšå¤šå¸§çš„åŒ¹é…ã€‚å…ˆåˆå§‹åŒ–ä¸€ä¸ªSfMå’Œä¸€ä¸ªé«˜æ–¯ï¼Œç„¶åä¼˜åŒ–é«˜æ–¯+è¿›è¡Œç¨ å¯†åŒ–ï¼Œä»é«˜æ–¯ä¸­å°†SfMçš„3Dç‚¹ç»™æŠ•å½±åˆ°æ–°çš„å¸§ï¼Œå»ºç«‹æ–°çš„matchå…³ç³»ï¼Œæœ€åå†ç”¨ç½‘ç»œå¯¹ç‚¹çš„tracksè¿›è¡Œrefinementï¼Œç”¨BAå¾—åˆ°refined SfMã€‚<br>
  å¯ä»¥å­¦å­¦ï¼šæ€ä¹ˆç»“åˆGSåšçš„track extensionï¼›å¯ä»¥å‚è€ƒtrack refinementçš„ç½‘ç»œè®¾è®¡ã€‚<br>
  æ²¡å¼€æºã€‚<br>
  å¯ä»¥ä»è¿™ç¯‡äº†è§£ä¸€ä¸‹sfmçš„å‡ ç±»æ–¹æ³•ï¼šdetector-based(colmap, pixsfm etc.), semi-dense matching(detector-free)(LoFTR/AspanTrans/MatchFormer + PixSfM/DFSfM), dense matching(RoMa/DKM + DFSfM/ours)ï¼ŒåŒæ—¶é¡ºä¾¿å¯ä»¥äº†è§£åŒ¹é…çš„æ–¹æ³•ã€‚

### 0301

- [MambaGlue: Fast and Robust Local Feature Matching With Mamba](https://arxiv.org/pdf/2502.00462)<br>
  æ ¸å¿ƒè®¾è®¡äº†MambaAttentionï¼Œä¸€ç§åŸºäºmambaçš„self-attentionå±‚ã€‚æé«˜äº†è¿è¡Œæ•ˆç‡ã€‚

### 0313 CVPR'25

#### SLAMç›¸å…³

- [MAGiC-SLAM: Multi-Agent Gaussian Globally Consistent SLAM](https://arxiv.org/pdf/2411.16785)<br>
  å¤šæ™ºèƒ½ä½“3dgs SLAMã€‚
- [MNE-SLAM: Multi-Agent Neural SLAM for Mobile Robots]()<br>
- [SLAM3R: Real-Time Dense Scene Reconstruction from Monocular RGB Videos](https://www.arxiv.org/pdf/2412.09401)<br>
  é™ˆå®æƒè€å¸ˆç»„çš„å·¥ä½œã€‚æŠŠDUSt3Ræ‰©å±•æˆäº†SLAMã€‚ä¸»è¦ç”¨sliding windowæ„å»ºsubmapï¼Œç„¶ååšå¯¹é½ã€‚
- [MASt3R-SLAM: Real-Time Dense SLAM with 3D Reconstruction Priors]()

#### å…¶ä»–

- [**VGGT: Visual Geometry Grounded Transformer**](https://www.arxiv.org/pdf/2503.11651)<br>
  feed-forward networkï¼ŒåŒæ—¶å¯¹ä»»æ„æ•°é‡çš„å›¾åƒè¾“å…¥ï¼Œè¾“å‡ºç›¸æœºå‚æ•°ã€ç‚¹äº‘ã€æ·±åº¦å›¾ã€3Dç‚¹è·Ÿè¸ªã€‚åœ¨64å¼ A100ä¸Šè®­ç»ƒ9å¤©ã€‚<br>
  ç”¨tapvid_davisçš„ä¸€äº›åºåˆ—æµ‹äº†ä¸‹ï¼Œfailure caseæœ‰soapbox, scooter-black, pigs, parkour, motocross-jump, mbike-trickç­‰<br>
  è¿˜è¡Œçš„åºåˆ—loading, libbyç­‰<br>

  ä¸èƒ½æœ‰æ•ˆçš„å»é™¤åŠ¨æ€ç‰©ä½“çš„å½±å“ï¼Œå¯¹äºä¸€äº›éç»“æ„åŒ–åœºæ™¯ï¼ˆé‡å¤–ç­‰ï¼‰é‡å»ºä¸å¥½ï¼Œå¯¹äºåƒparkourè¿™æ ·è¿˜ç®—æœ‰ç»“æ„çš„ï¼Œä½†æ— çº¹ç†è¾ƒå¤§ï¼Œè§†è§’è½¬åŠ¨è¾ƒå¤§çš„é‡å»ºå¾—ä¹Ÿä¸å¥½ã€‚<br>
  æ„Ÿè§‰å¯¹äºè§†è§’è½¬åŠ¨è¿‡å¤§çš„ï¼Œé‡å»ºæ•ˆæœéƒ½ä¸å¤ªå¥½ã€‚<br>
  å¯¹äºå®¤å¤–åœºæ™¯ï¼Œå½“åŒ…å«ä¸€äº›æ·±åº¦è¾ƒè¿œçš„éƒ¨åˆ†ï¼Œæ•ˆæœä¸å¥½ã€‚

- [**MATCHA: Towards Matching Anything**](https://arxiv.org/pdf/2501.14945)<br>
  æå‡ºäº†ä¸€ç§ç»Ÿä¸€çš„â€œèåˆäº†å‡ ä½•ç‰¹å¾ã€è¯­ä¹‰ç‰¹å¾ã€å¯¹è±¡ç‰¹å¾â€çš„è§†è§‰ç‰¹å¾ï¼Œåœ¨å‡ ä½•åŒ¹é…ã€è¯­ä¹‰åŒ¹é…ã€ç‚¹çš„æ—¶åºtrackingä»»åŠ¡ä¸Šè¡¨è¾ƒå¥½ã€‚ä¸»è¦åŸºäºäº†DIFTå’ŒDINOv2è¿™ä¸¤ä¸ªå·¥ä½œã€‚<br>
  å›å¤´è¯»ä¸€ä¸‹ï¼šå½“å‰è§†è§‰ç‰¹å¾çš„ç›¸å…³å·¥ä½œï¼Œmatchingç›¸å…³çš„ï¼ˆå‡ ä½•ã€è¯­ä¹‰ï¼‰ã€point trackingã€ä»¥åŠè§†è§‰åŸºç¡€æ¨¡å‹ã€‚


### 0422

- [**TAPIP3D: Tracking Any Point in Persistent 3D Geometry**](https://www.arxiv.org/abs/2504.14717v1)<br>
  æŠŠå›¾åƒçš„2dç‰¹å¾unprojectæˆ3dç‰¹å¾äº‘ï¼Œåœ¨ç‰¹å¾äº‘ä¸Šç”¨knnåšattentionã€‚ç”¨äº†Mogeåšdepth estimatorï¼ŒMegaSaMä¼°è®¡ç›¸æœºå†…å¤–å‚ã€‚point tracksçš„iterativeæ›´æ–°å‚è€ƒäº†CoTracker3ã€‚<br>
  åœ¨3dç‚¹äº‘ä¸Šå–knnæ¯”è¾ƒæ…¢ï¼Œå¯ä»¥ä¼˜åŒ–(æ¯”å¦‚å‚è€ƒMASt3R-SLAMçš„ä¼˜åŒ–æ–¹æ³•ï¼Ÿ)<br>

### 0423

- [**Back on Track: Bundle Adjustment for Dynamic Scene Reconstruction**](https://arxiv.org/pdf/2504.14516)<br>
  LEAP-VOä½œè€…çš„æ–°ä½œï¼Œç»§ç»­ç”¨TAPåšåŠ¨æ€VOã€‚ç”¨äº†depthä¼°è®¡ç½‘ç»œ(ZoeDepth)ï¼Œå¯¹äºåŠ¨æ€ç‰©ä½“ä¸Šçš„pointåœ¨ä¼°è®¡trackæ—¶ï¼Œå¤šä¼°è®¡äº†ä¸€ä¸ªdynamic motionï¼ŒæŠŠåŠ¨æ€ç‰©ä½“çš„trackç»™è§£è€¦/æ¢å¤æˆé™æ€åœºæ™¯çš„trackã€‚ï¼Œå†ç»“åˆæ·±åº¦åšBAã€‚<br>
- [**Relative Pose Estimation through Affine Corrections of Monocular Depth Priors**](https://www.arxiv.org/pdf/2501.05446)<br>
  CVPR2025 highlight<br>
  å½“å‰æ·±åº¦ä¼°è®¡æ¨¡å‹ï¼Œåœ¨ä½¿ç”¨çš„æ—¶å€™ä»…ä»…è€ƒè™‘äº†scale factorï¼Œæ²¡è€ƒè™‘shift factorã€‚æ‰€ä»¥è¿™ç¯‡æ–‡ç« æå‡ºåœ¨æ±‚è§£/åŒ¹é…çš„æ—¶å€™ï¼ŒåŒæ—¶è¦è€ƒè™‘scaleå’Œshift factorã€‚è¿™ä¸ªæƒ³æ³•æˆ–è®¸ä¸æ˜¯å®ƒç¬¬ä¸€ä¸ªæå‡ºçš„ï¼Œä½†æ˜¯å®ƒç”¨è¿™ä¸ªæƒ³æ³•è®¾è®¡äº†å‡ ç§æƒ…å†µä¸‹çš„æ±‚è§£å™¨ï¼ˆcalibratedå’Œuncalibratedç­‰ï¼‰<br>
  ï¼ˆè¿™ç¯‡æ–‡ç« è¯´ï¼‰è¿™ä¸ªé—®é¢˜åº”è¯¥æ˜¯ç”±è®­ç»ƒæ—¶çš„æŸå¤±å‡½æ•°è®¾è®¡é—®é¢˜å¼•å…¥çš„ã€‚<br>
  ä¹‹å‰çš„å·¥ä½œï¼Œæ¯”å¦‚MonoSDFä¸­ï¼Œè®¾è®¡çš„depthä¼°è®¡ç½‘ç»œå…¶å®å°±æ˜¯affine invariantçš„ã€‚<br>

### 0503

å•ç›®åŠ¨æ€åœºæ™¯4dé‡å»ºç›¸å…³:

- [**MegaSaM: Accurate, Fast and Robust Structure and Motion from Casual Dynamic Videos**](https://mega-sam.github.io/)<br>
  åœ¨å¤§é‡æ•°æ®ä¸Šè®­ç»ƒï¼Œå¯¹ä»»æ„åŠ¨æ€è§†é¢‘è¿›è¡Œé‡å»º+ç›¸æœºä½å§¿ä¼°è®¡ã€‚<br>
  cvpr2025 best paperã€‚<br>
- [**TAPIP3D: Tracking Any Point in Persistent 3D Geometry**](https://www.arxiv.org/abs/2504.14717v1)<br>
  æŠŠå›¾åƒçš„2dç‰¹å¾unprojectæˆ3dç‰¹å¾äº‘ï¼Œåœ¨ç‰¹å¾äº‘ä¸Šç”¨knnåšattentionã€‚ç”¨äº†Mogeåšdepth estimatorï¼ŒMegaSaMä¼°è®¡ç›¸æœºå†…å¤–å‚ã€‚point tracksçš„iterativeæ›´æ–°å‚è€ƒäº†CoTracker3ã€‚<br>
  åœ¨3dç‚¹äº‘ä¸Šå–knnæ¯”è¾ƒæ…¢ï¼Œå¯ä»¥ä¼˜åŒ–(æ¯”å¦‚å‚è€ƒMASt3R-SLAMçš„ä¼˜åŒ–æ–¹æ³•ï¼Ÿ)<br>
  æ•ˆæœçœ‹ä¸Šå»è¿˜è¡Œï¼Œ

### 0614

Point tracking in CVPR2025

- [GS-DiT: Advancing Video Generation with Dynamic 3D Gaussian Fields through Efficient Dense 3D Point Tracking](https://arxiv.org/pdf/2501.02690)
- [Exploring Temporally-Aware Features for Point Tracking](https://arxiv.org/pdf/2501.12218)<br>
  ä¸€ä¸ªé’ˆå¯¹point trackingé—®é¢˜æ”¹è¿›çš„DIVOv2ç½‘ç»œï¼Œå¯ä»¥èšåˆæ—¶åºçš„featureï¼Œå¾—åˆ°çš„featureå¯ä»¥ç›´æ¥æ‹¿æ¥ç®—correlation mapã€‚<br>
- [Tracktention: Leveraging Point Tracking to Attend Videos Faster and Better](https://arxiv.org/pdf/2503.19904)
- [TimeTracker: Event-based Continuous Point Tracking for Video Frame Interpolation with Non-linear Motion](https://arxiv.org/pdf/2505.03116)


### 0628

- [LiVOS: Light Video Object Segmentation with Gated Linear Matching](https://www.alphaxiv.org/abs/2411.02818v1)<br>
  è§†é¢‘ç‰©ä½“åˆ†å‰²ã€‚æ”¹è¿›äº†ç©ºé—´-æ—¶é—´è®°å¿†ç½‘ç»œï¼ˆSTMï¼‰ï¼Œå…¶ä¸­ç”¨linear matchingæ›¿ä»£äº†ä¼ ç»Ÿstmä¸­çš„softmaxï¼›åŒæ—¶å¼•å…¥äº†gated linear matchingæœºåˆ¶ã€‚<br>
  ç½‘ç»œç»“æ„å’Œæ”¹åŠ¨æ€è·¯å¯ä»¥å‚è€ƒä¸€ä¸‹ã€‚
- [MINIMA: Modality Invariant Image Matching](https://arxiv.org/abs/2412.19412)<br>
  å¤šæ¨¡æ€å›¾åƒåŒ¹é…ã€‚ç”¨äº†ä¸€ä¸ªç”Ÿæˆæ¨¡å‹å»ç”Ÿæˆå¤šæ¨¡æ€å›¾åƒï¼Œæå‡ºäº†ä¸€å¥—æ¡†æ¶å¯ä»¥å¾®è°ƒloftr/lightglueç­‰ç¨€ç–/åŠç¨€ç–/ç¨ å¯†æ–¹æ³•ã€‚å¼€æºçš„ã€‚<br>
  å’Œè–›é£çš„matchaè€ƒè™‘çš„ä»»åŠ¡ç±»ä¼¼ï¼Œä½†æ˜¯æ€è·¯ä¸åŒã€‚<br>


### 0703

è¦ä¸è¦è¯•è¯•track-onåšvoï¼Œè§£å†³çº¯æ—‹è½¬é—®é¢˜ï¼Ÿåœºæ™¯æ˜¯å¤´æˆ´å¼è®¾å¤‡ï¼Œæ•°æ®é›†æ˜¯egopointsæˆ–è€…epic-fieldsã€‚

https://data.bris.ac.uk/data/dataset/3l8eci2oqgst92n14w2yqi5ytu<br>
https://data.bris.ac.uk/data/dataset/3h91syskeag572hl6tvuovwv4d<br>
https://epic-kitchens.github.io/2025<br>

çº¯æ—‹è½¬ç›¸å…³çš„æ–‡ç« ï¼š

- [Equivalent Constraints for Two-View Geometry: Pose Solution/Pure Rotation Identification and 3D Reconstruction](https://arxiv.org/pdf/1810.05863v1)<br>
  2019å¹´çš„æ–‡ç« <br>
- [RD-VIO: Robust Visual-Inertial Odometry for Mobile Augmented Reality in Dynamic Environments](https://www.alphaxiv.org/html/2310.15072v3)<br>
  24å¹´çš„æ–‡ç« ï¼Œç« å›½å³°è€å¸ˆç»„çš„ã€‚å¯¹äºè§†è§‰æœ‰çº¯æ—‹è½¬åˆ¤å®š+å»¶è¿Ÿä¸‰è§’åŒ–çš„æ“ä½œï¼Œå¯ä»¥å‚è€ƒä¸€ä¸‹ã€‚


### 0705

æ‰¾ä¸€ä¸‹å¤´æˆ´ç›¸æœº/vr/arä¹‹ç±»çš„æ•°æ®é›†

- epic-fields
- [WHU-Helmet Dataset](https://github.com/kafeiyin00/WHU-HelmetDataset?tab=readme-ov-file)
- [Ariaç³»åˆ—](https://www.projectaria.com/datasets/aea/)
- [Roller Coaster SLAM Dataset](https://github.com/Factor-Robotics/Roller-Coaster-SLAM-Dataset)
- [SimXR](https://arxiv.org/pdf/2403.06862v1)
- [ADVIO](https://github.com/AaltoVision/ADVIO)<br>
  DPVOåœ¨advio_01åºåˆ—ä¸Šå¾ˆå·®ï¼Œè¿™ä¸ªåºåˆ—ä¸­é—´æœ‰ä¸€æ®µåç”µæ¢¯ï¼Œç”»é¢ä¸­åªæœ‰æ‰¶æ¢¯å°é˜¶ï¼Œdpvoä»¥ä¸ºç›¸æœºæ²¡æœ‰ç§»åŠ¨ï¼Œå®é™…ä¸Šåœ¨ä¸Šå‡ã€‚<br>
  python demo.py --imagedir="/media/knocking/Expansion/datasets/advio/advio-01/iphone/frames.mov" --calib="/media/knocking/Expansion/datasets/advio/ADVIO/calibration/iphone-02.txt" --name advio_01 --viz --save_trajectory <br>
- [TUM-VIE](https://cvg.cit.tum.de/data/datasets/visual-inertial-event-dataset)<br>
  DPVOåœ¨running-hardåºåˆ—ä¸Šå¾ˆå·®ï¼Œè¿™ä¸ªåºåˆ—è¿åŠ¨æ¨¡ç³Šå¾ˆå¤šï¼Œäººæ‹¿ç€ç›¸æœºè·‘å¾—å¾ˆå¿«ã€‚<br>
  python demo.py --imagedir /media/knocking/Expansion/datasets/TUM_VIE/running-hard-vi_gt_data/left_images --calib /media/knocking/Expansion/datasets/TUM_VIE/calibB_left_1024x1024.txt --name "running-hard" --viz --save_trajectory <br>
  track-onåœ¨è¿åŠ¨æåº¦æ¨¡ç³Šçš„æƒ…å†µä¸‹ä¹Ÿå¾ˆå·®ï¼Œä»¥åŠåœ¨è¿™ç§åœºæ™¯ä¸‹å¦‚ä½•é€‰æ‹©queryéœ€è¦å¥½å¥½é€‰ä¸€ä¸‹ã€‚


### 0716

[ICCV'25 paperlist](https://iccv.thecvf.com/Conferences/2025/AcceptedPapers)

**Trackç›¸å…³ï¼š**

- [BlinkTrack: Feature Tracking over 80 FPS via Events and Images](https://arxiv.org/pdf/2409.17981)
- A Linear N-Point Solver for Structure and Motion from Asynchronous Tracks
- [SpatialTrackerV2: Advancing 3D Point Tracking with Explicit Camera Motion](https://arxiv.org/pdf/2507.12462)
- [Tracking Tiny Drones against Clutter: Large-Scale Infrared Benchmark with Motion-Centric Adaptive Algorithm]
- [Language Decoupling with Fine-grained Knowledge Guidance for Referring Multi-object Tracking]
- [GSOT3D: Towards Generic 3D Single Object Tracking in the Wild](https://arxiv.org/pdf/2412.02129)
- [Is Tracking really more challenging in First Person Egocentric Vision?]
- [XTrack: Multimodal Training Boosts RGB-X Video Object Trackers](https://arxiv.org/pdf/2405.17773)
- LA-MOTR: End-to-End Multi-Object Tracking by Learnable Association
- MVTrajecter: Multi-View Pedestrian Tracking with Trajectory Motion Cost and Trajectory Appearance Cost
- [**Online Dense Point Tracking with Streaming Memory**](https://arxiv.org/pdf/2503.06471)<br>
  [github](https://github.com/DQiaole/SPOT)
- [**TrackAny3D: Transferring Pretrained 3D Models for Category-unified 3D Point Cloud Tracking**](http://www.cssclab.cn/downloadfile/2025/TrackAny3D_Transferring%20Pretrained%203D%20Models%20for%20Category-unified%203D%20Point%20Cloud%20Tracking.pdf)
- Inter Inertial Poser: Multi-Human Motion Tracking from Sparse Inertial Sensors and Pairwise Inter-Sensor Distances 
- SMSTracker: Tri-path Score Mask Sigma Fusion for Multi-Modal Tracking
- [St4RTrack: Simultaneous 4D Reconstruction and Tracking in the World](https://arxiv.org/pdf/2504.13152)
- [General Compression Framework for Efficient Transformer Object Tracking](https://arxiv.org/pdf/2409.17564)
- [Street Gaussians without 3D Object Tracker](https://arxiv.org/pdf/2412.05548)
- [Event-aided Dense and Continuous Point Tracking: Everywhere and Anytime](https://openreview.net/pdf?id=1GIVx7COef)
- [CoTracker3: Simpler and Better Point Tracking by Pseudo-Labelling Real Videos](https://arxiv.org/pdf/2410.11831)
- COVTrack: Continuous Open-Vocabulary Multi-Object Tracking via Adaptive Multi-Cue Fusion
- [UMDATrack: Unified Multi-Domain Adaptive Tracking Under Adverse Weather Conditions](https://arxiv.org/pdf/2507.00648)
- CAT: A Unified Click-and-Track Framework for Realistic Tracking
- [Attention to Trajectory: Trajectory-Aware Open-Vocabulary Tracking](https://arxiv.org/pdf/2503.08145)
- [What You Have is What You Track: Adaptive and Robust Multimodal Tracking]
- [Multi-View 3D Point Tracking](https://arxiv.org/pdf/2508.21060)
- MATE: Motion-Augmented Temporal Consistency for Event-based Point Tracking
- M$^2$EIT:Multi-Domain Mixture of Experts for Robust Neural Inertial Tracking
- [Efficient Track Anything](https://arxiv.org/pdf/2411.18933)<br>
  [github](https://github.com/yformer/EfficientTAM)<br>
- [AllTracker: Efficient Dense Point Tracking at High Resolution](https://arxiv.org/pdf/2506.07310)<br>
  [github.io](https://alltracker.github.io/)<br>
- ASCENT: Annotation-free Self-supervised Contrastive Embeddings for 3D Neuron Tracking in Fluorescence Microscopy
- [Temporal Unlearnable Examples: Preventing Personal Video Data from Unauthorized Exploitation by Object Tracking](https://arxiv.org/pdf/2507.07483)
- [VOVTrack: Exploring the Potentiality in Raw Videos for Open-Vocabulary Multi-Object Tracking](https://arxiv.org/pdf/2410.08529)
- [**Back on Track: Bundle Adjustment for Dynamic Scene Reconstruction**](https://arxiv.org/pdf/2504.14516)
- ReTracker: Exploring Image Matching for Robust Online Any Point Tracking
- [Decouple and Track: Benchmarking and Improving Video Diffusion Transformers For Motion Transfer](https://arxiv.org/pdf/2503.17350)
- [TrackVerse: A Large-scale Dataset of Object Tracks for Visual Representation Learning](https://github.com/MMPLab/TrackVerse)
- [TAPNext: Tracking Any Point (TAP) as Next Token Prediction](https://arxiv.org/pdf/2504.05579)
- [CoopTrack: Exploring End-to-End Learning for Efficient Cooperative Sequential Perception](https://github.com/zhongjiaru/CoopTrack)

**Odometryç›¸å…³:**

- [Splat-LOAM: Gaussian Splatting LiDAR Odometry and Mapping](https://arxiv.org/pdf/2503.17491)

**SLAMç›¸å…³ï¼š**

- [SuperEvent: Cross-Modal Learning of Event-based Keypoint Detection for SLAM](https://arxiv.org/pdf/2504.00139)
- [Outdoor Monocular SLAM with Global Scale-Consistent 3D Gaussian Pointmaps](https://arxiv.org/pdf/2507.03737)
- [SEGS-SLAM: Structure-enhanced 3D Gaussian Splatting SLAM with Appearance Embedding](https://segs-slam.github.io/)
- [DyGS-SLAM: Real-Time Accurate Localization and Gaussian Reconstruction for Dynamic Scenes]()
- [ToF-Splatting: Dense SLAM using Sparse Time-of-Flight Depth and Multi-Frame Integration](https://arxiv.org/pdf/2504.16545)
- [Benchmarking Egocentric Visual-Inertial SLAM at City Scale]()
- [4D Gaussian Splatting SLAM](https://arxiv.org/pdf/2503.16710)
- [Underwater Visual SLAM with Depth Uncertainty and Medium Modeling]()

**keypointç›¸å…³ï¼š**

- [RIPE: Reinforcement Learning on Unlabeled Image Pairs for Robust Keypoint Extraction](https://arxiv.org/pdf/2507.04839)
- SuperEvent: Cross-Modal Learning of Event-based Keypoint Detection for SLAM
- Towards Annotation-Free Evaluation: KPAScore for Human Keypoint Detection
- VoxelKP: A Voxel-based Network Architecture for Human Keypoint Estimation in LiDAR Data
- [ZeroKey: Point-Level Reasoning and Zero-Shot 3D Keypoint Detection from Large Language Models](https://arxiv.org/pdf/2412.06292)
- [ReassembleNet: Learnable Keypoints and Diffusion for 2D Fresco Reconstruction](https://arxiv.org/pdf/2505.21117)
- [Sequential keypoint density estimator: an overlooked baseline of skeleton-based video anomaly detection](https://arxiv.org/pdf/2506.18368)
- [Doodle Your Keypoints: Sketch-Based Few-Shot Keypoint Detection](https://arxiv.org/pdf/2507.07994)

**matchingç›¸å…³ï¼š**

- [Towards Open-World Generation of Stereo Images and Unsupervised Matching](https://arxiv.org/pdf/2503.12720)
- Focal Plane Visual Feature Generation and Matching on a Pixel Processor Array
- [Diving into the Fusion of Monocular Priors for Generalized Stereo Matching](https://arxiv.org/pdf/2505.14414)
- Partially Matching Submap Helps: Uncetainty Modeling and Propagation for Text to Point Cloud Localization
- [Learning Few-Step Diffusion Models by Trajectory Distribution Matching](https://arxiv.org/pdf/2503.06674)
- [MAVFlow: Preserving Paralinguistic Elements with Conditional Flow Matching for Zero-Shot AV2AV Multilingual Translation](https://arxiv.org/pdf/2503.11026)
- [RobuSTereo: Robust Zero-Shot Stereo Matching under Adverse Weather](https://arxiv.org/pdf/2507.01653v1)
- [EMatch: A Unified Framework for Event-based Optical Flow and Stereo Matching](https://arxiv.org/pdf/2407.21735)
- MDP-Omni: Parameter-free Multimodal Depth Prior-based Sampling for Omnidirectional Stereo Matching
- SGAD: Semantic and Geometric-aware Descriptor for Local Feature Matching
- [Learning Dense Feature Matching via Lifting Single 2D Image to 3D Space]()
- [BANet: Bilateral Aggregation Network for Mobile Stereo Matching](https://arxiv.org/pdf/2503.03259)
- [Learning Robust Stereo Matching in the Wild with Selective Mixture-of-Experts](https://arxiv.org/pdf/2507.04631)
- [**Stereo Any Video: Temporally Consistent Stereo Matching**](https://arxiv.org/pdf/2503.05549)
- [Global Regulation and Excitation via Attention Tuning for Stereo Matching]()
- [ZeroStereo: Zero-shot Stereo Matching from Single Images](https://github.com/Windsrain/ZeroStereo?tab=readme-ov-file)
- CasP: Improving Semi-Dense Feature Matching Pipeline Leveraging Cascaded Correspondence Priors for Guidance
- [POMATO: Marrying Pointmap Matching with Temporal Motions for Dynamic 3D Reconstruction](https://arxiv.org/pdf/2504.05692)
- [ArgMatch: Adaptive Refinement Gathering for Efficient Dense Matching]()
- [**CoMatch: Dynamic Covisibility-Aware Transformer for Bilateral Subpixel-Level Semi-Dense Image Matching**](https://arxiv.org/pdf/2503.23925)
- [**EDM: Efficient Deep Feature Matching**](https://arxiv.org/pdf/2503.05122)
- [**Mind the Gap: Aligning Vision Foundation Models to Image Feature Matching**](https://www.arxiv.org/pdf/2507.10318v1)
- [Fast Globally Optimal and Geometrically Consistent 3D Shape Matching](https://arxiv.org/pdf/2504.06385)
- ReTracker: Exploring Image Matching for Robust Online Any Point Tracking

### 0719

å¾—çœ‹çœ‹IROSå’ŒICRAçš„list

- [Self-supervised Pretraining and Finetuning for Monocular Depth and Visual Odometry](https://arxiv.org/pdf/2406.11019)
- [Self-Supervised Learning of Monocular Visual Odometry and Depth with Uncertainty-Aware Scale Consisten](https://ieeexplore.ieee.org/stamp/stamp.jsp?tp=&arnumber=10610075)


### 0721

è¿™ä¸ªå¾—çœ‹ä¸€ä¸‹<br>

- [$\pi^3$: Scalable Permutation-Equivariant Visual Geometry Learnin](https://arxiv.org/pdf/2507.13347)<br>


### 0722

æ¸…åæœ€è¿‘å‡ºäº†ä¸ªStreamVGGTï¼Œå¥½åƒæ˜¯videoè¾“å…¥èŒƒå¼/å¢é‡å¼çš„ï¼Œå¯ä»¥çœ‹ä¸€ä¸‹<br>

- [Streaming 4D Visual Geometry Transformer](https://arxiv.org/pdf/2507.11539), [ä¸»é¡µ](https://wzzheng.net/StreamVGGT/)<br>

è¿™ä¸ªç»„å¥½åƒæ¯”è¾ƒå¤šonline memoryçš„æ–‡ç« ï¼Œä¸€ä½œ[Wenzhao Zhengçš„ä¸»é¡µ](https://wzzheng.net/)


### 0807

VLAçš„ä¸€ä¸ªç»¼è¿°<br>

- [A Survey on Vision-Language-Action Models: An Action Tokenization Perspective](https://www.arxiv.org/pdf/2507.01925)


### 0901

- [Efficient Motion Prompt Learning for Robust Visual Tracking](https://www.arxiv.org/pdf/2505.16321v1)<br>
  é‡Œé¢å…³äºç©ºé—´ä½ç½®ç¼–ç å’Œæ—¶é—´ä½ç½®ç¼–ç çš„å°trickå›å¤´å¯ä»¥è¯•è¯•ï¼ˆEq.(3)ï¼‰ã€‚<br>


### 0904

#### [SpatialTrackerV2: 3D Point Tracking Made Easy](https://github.com/henry123-boy/SpaTrackerV2)

tag: `ICCV'25`, `3D`, `multi-view`

è¯¦ç»†è¯»ä¸€ä¸‹SpatialTrackerv2çš„è®ºæ–‡ã€‚

3. ä¼°è®¡æŸ¥è¯¢ç‚¹çš„3Dè½¨è¿¹$\mathcal{T}$æ—¶ï¼Œå°†å…¶åˆ†è§£æˆäº†ç›¸æœºè¿åŠ¨$\mathcal{T}_{ego}$å’Œç‰©ä½“è¿åŠ¨$\mathcal{T}_{object}$ä¸¤éƒ¨åˆ†ã€‚<br>
   
   1. $\mathcal{T}_{ego}$
      
      åˆå§‹çš„æ·±åº¦ä¼°è®¡å’Œç›¸æœºè¿åŠ¨ï¼šåŸºäºVGGTã€‚
  
   2. è”åˆä½å§¿ä¼˜åŒ–
      
      æå‡º**SyncFormer**ï¼Œè¿­ä»£åœ°åŒæ—¶ä¼˜åŒ–ï¼šUVç©ºé—´çš„è½¨è¿¹$\mathcal{T}^{2d}$ï¼›ç›¸æœºåæ ‡ç³»çš„è½¨è¿¹$\mathcal{T}^{3d}$ï¼›å¯è§åº¦æƒé‡$p^{vis}$ï¼›åŠ¨æ€æƒé‡$p^{dyn}$ã€‚ç›¸æœºçš„ä½å§¿$\mathcal{P}$ç”¨BAå¾—åˆ°ã€‚

      2D embeddingså’ŒCotracker3ä¸€æ ·ï¼Œ3D embeddingsåŒ…å«3dç›¸å…³æ€§ç‰¹å¾ç­‰ã€‚å…¶ä¸­ï¼Œ3dç›¸å…³æ€§ç‰¹å¾æ˜¯åœ¨å½’ä¸€åŒ–point mapä¸­å½“å‰çš„ç‚¹ä¸é‚»å±…ç‚¹çš„ç›¸å¯¹ä½ç§»è¿›è¡Œharmonic positional encodingå¾—åˆ°çš„ï¼Œå¹¶ä¸”åœ¨å¤šåˆ†è¾¨ç‡ä¸Šéƒ½è¿›è¡Œäº†ç‰¹å¾ç¼–ç ã€‚

      SyncFormerè°ƒæ•´å®Œä¸€è½®$\mathcal{T}_{k+1}^{2d}, \mathcal{T}_{k+1}^{3d}, p_{k+1}^{dyn}, p_{k+1}^{vis}$åï¼Œé€šè¿‡Procrustes analysiså¯¹é½3dè½¨è¿¹åˆ°ä¸–ç•Œåæ ‡ç³»ï¼Œæ„å»ºBAä¼˜åŒ–å¾—åˆ°ç›¸æœºä½å§¿$\mathcal{P}_{k+1}$ã€‚
    
   3. è®­ç»ƒ

      åœ¨17ä¸ªæ•°æ®é›†ä¸Šè®­ç»ƒã€‚ï¼ˆå•Šâ€¦â€¦å¥½å¤šğŸ˜å¥½å–œæ¬¢ï¼‰åˆ†ä¸ºä¸‰å¤§ç±»ï¼šå¸¦track gt, pose gtçš„RGB-Dæ•°æ®ï¼›å¸¦pose gtçš„RGB-Dæ•°æ®ï¼›ä»…æœ‰pose gtæˆ–æ— æ ‡æ³¨çš„ã€‚

      è®­ç»ƒåˆ†ä¸‰ä¸ªé˜¶æ®µã€‚ä¸€é˜¶æ®µï¼Œè®­ç»ƒå‰ç«¯çš„ç½‘ç»œï¼ˆVGGTæ”¹çš„ä¼°è®¡è§†é¢‘æ·±åº¦å’Œåˆå§‹ç›¸æœºä½å§¿ï¼‰ï¼Œ64å¼ H20ã€‚äºŒé˜¶æ®µï¼Œè®­ç»ƒSyncFormerï¼Œ8å¼ H20è®­3å¤©ã€‚ä¸‰é˜¶æ®µï¼Œå›ºå®šå‰ç«¯ç½‘ç»œä¸­çš„äº¤æ›¿æ³¨æ„åŠ›å±‚ï¼Œè®­æ•´ä¸ªæ¡†æ¶ã€‚

4. å®éªŒç»“æœ
   
   ä¸»è¦ç»“æœæ˜¯åœ¨TAPIP-3Dä¸Šå¯¹æ¯”3d trackingçš„ç²¾åº¦ã€‚åœ¨3d point trackingä¸Šæ˜¯sotaã€‚

   æ·±åº¦ä¼°è®¡ï¼Œåœ¨å®¤å†…(tum dyn, bonn, sintel)å’Œå®¤å¤–(kitti, sintel)å«åŠ¨æ€ç‰©ä½“çš„æ•°æ®é›†ï¼Œæ¯”VGGTå’ŒMegaSamå¥½ï¼ˆå„æœ‰ä¼˜åŠ£ï¼‰ã€‚

   ç›¸æœºä½å§¿ä¼°è®¡ï¼Œåœ¨å®¤å†…å¤–ï¼ˆtum dyn, lightspeed, sintelï¼‰ï¼Œå’ŒMegaSamå·®ä¸å¤šã€‚

   2D trackingä¹Ÿæ˜¯SOTAã€‚




#### Related works about point tracking

Refer to `papers/point_tracking`
