{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Notebook","text":"<p>This is Knockning's personal notebook.</p> <p>\u8fd9\u91cc\u662fKnocking\u7684\u4e2a\u4eba\u7b14\u8bb0\u672c.</p>"},{"location":"about_this_notebook/","title":"About this notebook","text":"<p>Everytime when you write a new note... <pre><code>mkdocs build\nmkdocs gh-deploy\ngit add --all\ngit commit -m \"blablabla\"\ngit push   # add \"-u origin main\" for the first push\n</code></pre></p> <p>To preview the notebook locally... <pre><code>mkdocs serve\n</code></pre></p>"},{"location":"about_this_notebook/#about-mkdocs","title":"About mkdocs...","text":"<p>For full documentation visit mkdocs.org.</p>"},{"location":"about_this_notebook/#commands","title":"Commands","text":"<ul> <li><code>mkdocs new [dir-name]</code> - Create a new project.</li> <li><code>mkdocs serve</code> - Start the live-reloading docs server.</li> <li><code>mkdocs build</code> - Build the documentation site.</li> <li><code>mkdocs -h</code> - Print help message and exit.</li> </ul>"},{"location":"about_this_notebook/#project-layout","title":"Project layout","text":"<pre><code>mkdocs.yml    # The configuration file.\ndocs/\n    index.md  # The documentation homepage.\n    ...       # Other markdown pages, images and other files.\n</code></pre>"},{"location":"github/Deploy%20repo/","title":"Create a new github repository","text":"<p>Create a new repository</p> <pre><code>echo \"# notes\" &gt;&gt; README.md\ngit init\ngit add README.md\ngit commit -m \"first commit\"\ngit branch -M main\ngit remote add origin git@github.com:{MyName}/{RepoName}.git\ngit push -u origin main\n</code></pre> <p>Push an existing repo with command lines</p> <pre><code>git remote add origin git@github.com:{MyName}/{RepoName}.git\ngit branch -M main\ngit push -u origin main\n</code></pre>"},{"location":"papers/paper_notes/","title":"Paper notes","text":"<ul> <li> <p>SuperPrimitive: Scene Reconstruction at a Primitive Level</p> <p>\u8bed\u4e49\uff08\u5b9e\u4f8b\uff09+\u91cd\u5efa\u3002\u540c\u65f6\u505a\u5206\u5272+\u6cd5\u5411\u4f30\u8ba1\u3002\u5c55\u793a\u4e86\u7a20\u5bc6\u91cd\u5efa\u3001\u7a20\u5bc6VO\u3002</p> </li> </ul>"},{"location":"papers/research_diary/","title":"2024","text":""},{"location":"papers/research_diary/#0704","title":"0704","text":"<ul> <li>\u7528stable diffusion\u505afinetune\uff0c\u53ef\u4ee5\u7528\u4f4e\u5f00\u9500\u548c\u4e0d\u591a\u7684\u6570\u636e\u96c6\u505afinetune\u3002</li> </ul> <ul> <li>\u505adepth\u7684\uff1aRepurposing Diffusion-Based Image Generators for Monocular Depth Estimation (CVPR 2024)\uff0c\u53ef\u4ee5\u4ece\u91cc\u9762\u501f\u9274conditional\u7684\u7528\u6cd5\uff0c\u4ee5\u53ca\u5982\u4f55\u628adepth image\u8f6c\u6362\u5230\u9002\u5408diffusion\u7684\u6846\u67b6\uff1b\u505adense matching\u7684\uff1aDIFFUSION MODEL FOR DENSE MATCHING (ICLR 2024)\uff0c\u4ed6\u7528\u4e24\u5f20\u56fe\u7684global cost\u4f5c\u4e3acondition\uff0c\u4f46\u662f\u6846\u67b6\u8bbe\u8ba1\u4e0a\u8fd8\u662f\u6709\u70b9\u66b4\u529b\u3002</li> </ul>"},{"location":"papers/research_diary/#0705","title":"0705","text":"<ul> <li>DOT\uff08Matching 2D Images in 3D: Metric Relative Pose from Metric Correspondences\uff09\u4e3a\u5565\u6bd4RAFT\u548cCoTracker\u6548\u679c\u8fd8\u597d\uff1fDOT\u7684\u5b9e\u9a8c\u8bbe\u8ba1\u548c\u6545\u4e8b\u662f\u600e\u4e48\u8bb2\u7684\uff0c\u503c\u5f97\u770b\u4e00\u770b\u3002</li> </ul>"},{"location":"papers/research_diary/#0706","title":"0706","text":"<ul> <li> <p>\u7528covariance\u5efa\u6a21point tracks\u4e4b\u95f4\u7684\u5173\u8054\u6027\uff1f</p> <p>\u4e09\u4e2a\u597d\u5904\uff1a\u9c81\u68d2\uff08\u4ece\u56fe\u50cf\u4e2d\u5bf9\u70b9\u505atrack\uff0c\u5b66\u7684\u662f\\(\\delta I\\)\uff1b\u800c\u5b66\u4e60track\u4e4b\u95f4\u7684covariance\uff0c\u5b66\u7684\u662f\\(\\delta I\\)\u6574\u4f53\u7684\u5206\u5e03\u7279\u6027\uff09\uff1b\u9ad8\u6548\uff08\u51cf\u8f7b\u6570\u636e\u5197\u4f59\u548c\u5b66\u4e60\u8d1f\u62c5\uff0c\u53ef\u4ee5\u7528\u5c11\u91cf\u7684\u7a33\u5b9a\u7684\u70b9\uff0c\u8868\u8fbe\u6574\u5f20\u56fe\u91cc\u5176\u4ed6\u70b9\u7684\u8fd0\u52a8\u8d8b\u52bf\uff0c\u540c\u65f6\u4e5f\u53ef\u4ee5\u8868\u8fbe\u76f8\u673a\u7684\u8fd0\u52a8\u8d8b\u52bf\uff09\uff1b\u53ef\u4ee5\u505a\u9884\u6d4b\uff08\u5b66\u5230\u7684covariance\u53ef\u4ee5\u7528\u4f5c\u9884\u6d4bpoint\u5728\u4e0b\u4e00\u5e27\u91cc\u7684\u79fb\u52a8\uff09</p> <p>\u6570\u5b66\u65b9\u6cd5\u4e0a\u53c2\u8003Learning a Depth Covariance Function\uff0c\u770b\u770b\u4ed6\u600e\u4e48\u8fdb\u884c\u7684\u968f\u673a\u8fc7\u7a0b\u5efa\u6a21</p> <p>\u574f\u5904\uff1a\u90a3\u8fd9\u6837\u5c31\u8981\u8bb2point track\u7684\u6545\u4e8b\u4e86\uff1f\u4e0d\u7ba1\u662fpoint tracking\u8fd8\u662foptical flow\uff0c\u90fd\u975e\u5e38\u5173\u6ce8\u52a8\u6001\u7269\u4f53\u3002\u90a3\u8981\u505a\u52a8\u6001\u7269\u4f53\uff1f</p> </li> </ul> <ul> <li>\u8003\u8651\u7528covariance function\u505aoptical flow\uff1f\u8fd8\u662f\u505akeypoint matching\uff1f</li> </ul> <ul> <li>Image encoder\u53ef\u4ee5\u8003\u8651\u7528\u9884\u8bad\u7ec3\u7684DIVOv2\u3002</li> </ul> <ul> <li>\u5982\u679c\u505acovariance function+optical flow\uff0c\u90a3\u96be\u70b9\u5c31\u5728\u4e8e\uff1adepth covariance function\u662f\u7528\u7684UNet cnn\u7f51\u7edc\uff0cRAFT\u7528\u7684\u662fGRU\uff0c\u8fd9\u4e2a\u600e\u4e48\u8c03\u901a\u3002</li> </ul>"},{"location":"papers/research_diary/#0708","title":"0708","text":"<ul> <li>dust3r\uff1a\u80fd\u5426\u505a\u5230online\uff0c\u80fd\u5426\u505a\u5230sparse</li> </ul>"}]}